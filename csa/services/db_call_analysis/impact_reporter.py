"""
ì˜í–¥ë„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ

Markdown, Excel, JSON í˜•ì‹ì˜ ì˜í–¥ë„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
"""
from __future__ import annotations

import json
from pathlib import Path
from typing import Optional

from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter

from csa.models.impact import ImpactAnalysisResult
from csa.diagrams.impact import ImpactMermaidGenerator
from csa.utils.logger import get_logger

logger = get_logger(__name__)


class ImpactReporter:
    """ì˜í–¥ë„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°

    Markdown, Excel, JSON í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def generate_markdown(
        self,
        result: ImpactAnalysisResult,
        filepath: Path,
    ) -> bool:
        """Markdown ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            result: ImpactAnalysisResult ê°ì²´
            filepath: ì €ì¥ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            lines = []

            # 1. ë¶„ì„ ê°œìš”
            lines.append("# ì˜í–¥ë„ ë¶„ì„ ë³´ê³ ì„œ")
            lines.append("")
            lines.append("## 1. ë¶„ì„ ê°œìš”")
            lines.append(f"- **ë¶„ì„ ëŒ€ìƒ**: `{result.target_name}`")
            if result.project_name:
                lines.append(f"- **í”„ë¡œì íŠ¸**: {result.project_name}")
            else:
                lines.append("- **í”„ë¡œì íŠ¸**: ì „ì²´")
            lines.append(f"- **ë¶„ì„ ìœ í˜•**: {result.analysis_type}")
            lines.append(f"- **ë¶„ì„ ì¼ì‹œ**: {result.timestamp}")
            lines.append("")

            # 2. ì˜í–¥ë„ ìš”ì•½
            summary = result.summary
            lines.append("## 2. ì˜í–¥ë„ ìš”ì•½")
            lines.append("- **ì´ ì˜í–¥ ë²”ìœ„**:")
            lines.append(f"  - ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤: {summary.total_impacted_classes}ê°œ")
            lines.append(f"  - ì˜í–¥ë°›ëŠ” ë©”ì„œë“œ: {summary.total_impacted_methods}ê°œ")
            lines.append(f"  - ì˜í–¥ë°›ëŠ” íŒ¨í‚¤ì§€: {summary.total_impacted_packages}ê°œ")
            lines.append("- **ì˜í–¥ ê¹Šì´**:")
            lines.append(f"  - ìµœëŒ€ í˜¸ì¶œ ê¹Šì´: {summary.max_depth}")
            lines.append(f"  - í‰ê·  í˜¸ì¶œ ê¹Šì´: {summary.avg_depth}")

            # ë¦¬ìŠ¤í¬ ë“±ê¸‰
            risk_dist = summary.risk_distribution
            total_high = risk_dist.get("HIGH", 0)
            total_medium = risk_dist.get("MEDIUM", 0)
            total_low = risk_dist.get("LOW", 0)

            if total_high > 0:
                lines.append("- **ë¦¬ìŠ¤í¬ ë“±ê¸‰**: **HIGH** âš ï¸")
            elif total_medium > 0:
                lines.append("- **ë¦¬ìŠ¤í¬ ë“±ê¸‰**: **MEDIUM** âš ")
            else:
                lines.append("- **ë¦¬ìŠ¤í¬ ë“±ê¸‰**: **LOW** âœ“")

            lines.append(f"  - High: {total_high}ê°œ ë©”ì„œë“œ")
            lines.append(f"  - Medium: {total_medium}ê°œ ë©”ì„œë“œ")
            lines.append(f"  - Low: {total_low}ê°œ ë©”ì„œë“œ")
            lines.append("")

            # 3. ì˜í–¥ë„ íŠ¸ë¦¬ (Levelë³„)
            if result.impact_tree:
                lines.append("## 3. ì˜í–¥ë„ íŠ¸ë¦¬ (Levelë³„)")
                lines.append("")

                for level in sorted(result.impact_tree.keys()):
                    nodes = result.impact_tree[level]
                    if not nodes:
                        continue

                    if level == 1:
                        lines.append(f"### Level {level} (ì§ì ‘ ì˜í–¥ - Depth 0)")
                    else:
                        max_depth_in_level = max(node.depth for node in nodes)
                        lines.append(f"### Level {level} (ê°„ì ‘ ì˜í–¥ - Depth {max_depth_in_level})")

                    for node in nodes:
                        risk_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}.get(node.risk_grade, "âšª")

                        # íŒ¨í‚¤ì§€.í´ë˜ìŠ¤.ë©”ì„œë“œ
                        full_name = f"{node.package_name}.{node.class_name}.{node.method_name}"

                        # SQL ì •ë³´ (ìˆëŠ” ê²½ìš°)
                        if node.sql_id:
                            sql_info = f"({node.sql_type}, Complexity: {node.sql_complexity})"
                        else:
                            sql_info = ""

                        lines.append(f"- {risk_icon} **{full_name}** {sql_info}")

                    lines.append("")
            else:
                lines.append("## 3. ì˜í–¥ë„ íŠ¸ë¦¬")
                lines.append("ì˜í–¥ë°›ëŠ” ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                lines.append("")

            # 4. íŒ¨í‚¤ì§€ë³„ í†µê³„
            if result.package_summary:
                lines.append("## 4. íŒ¨í‚¤ì§€ë³„ í†µê³„")
                lines.append("")
                lines.append("| Package | í´ë˜ìŠ¤ ìˆ˜ | ë©”ì„œë“œ ìˆ˜ | í‰ê·  Depth | High Risk | Medium Risk | Low Risk |")
                lines.append("|---------|----------|----------|-----------|-----------|-------------|----------|")

                for pkg in result.package_summary:
                    lines.append(
                        f"| {pkg.package_name} "
                        f"| {pkg.impacted_classes} "
                        f"| {pkg.impacted_methods} "
                        f"| {pkg.avg_depth} "
                        f"| {pkg.risk_distribution.get('HIGH', 0)} "
                        f"| {pkg.risk_distribution.get('MEDIUM', 0)} "
                        f"| {pkg.risk_distribution.get('LOW', 0)} |"
                    )
                lines.append("")

            # 5. SQL ìƒì„¸ ì •ë³´ (í…Œì´ë¸” ë¶„ì„ ì‹œ)
            if result.sql_details:
                lines.append("## 5. SQL ìƒì„¸ ì •ë³´")
                lines.append("")
                lines.append("| SQL ID | Type | Mapper | Complexity | Query |")
                lines.append("|--------|------|--------|-----------|-------|")

                for sql in result.sql_details:
                    query_preview = sql.query_preview[:50] + "..." if sql.query_preview and len(sql.query_preview) > 50 else sql.query_preview or ""
                    query_preview_md = query_preview.replace("|", "\\|")  # íŒŒì´í”„ ì´ìŠ¤ì¼€ì´í”„

                    lines.append(
                        f"| {sql.sql_id} "
                        f"| {sql.sql_type} "
                        f"| {sql.mapper_class}.{sql.mapper_method} "
                        f"| {sql.complexity} "
                        f"| `{query_preview_md}` |"
                    )
                lines.append("")

            # 6. ê¶Œì¥ í…ŒìŠ¤íŠ¸ ë²”ìœ„
            if result.test_scope:
                lines.append("## 6. ê¶Œì¥ í…ŒìŠ¤íŠ¸ ë²”ìœ„")
                lines.append("")

                existing_tests = [item for item in result.test_scope if item.status == "ì¡´ì¬"]
                missing_tests = [item for item in result.test_scope if item.status == "ë¯¸ì¡´ì¬"]

                if existing_tests:
                    lines.append("### ê¸°ì¡´ í…ŒìŠ¤íŠ¸ (ì‹¤í–‰ ê¶Œì¥)")
                    for item in existing_tests:
                        lines.append(f"- âœ“ `{item.test_class}` (ë©”ì„œë“œ {item.test_method_count}ê°œ)")
                    lines.append("")

                if missing_tests:
                    lines.append("### í…ŒìŠ¤íŠ¸ ë¯¸ì¡´ì¬ (ì‘ì„± ê¶Œì¥)")
                    for item in missing_tests:
                        lines.append(f"- âš ï¸ `{item.impacted_class}` - í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ì—†ìŒ")
                    lines.append("")

                # í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
                total_classes = len(result.test_scope)
                tested_classes = len(existing_tests)
                coverage_pct = (tested_classes / total_classes * 100) if total_classes > 0 else 0
                lines.append(f"**í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: {tested_classes}/{total_classes} ({coverage_pct:.1f}%)")
                lines.append("")

            # 7. ë³€ê²½ ì‹œ ì£¼ì˜ì‚¬í•­
            lines.append("## 7. ë³€ê²½ ì‹œ ì£¼ì˜ì‚¬í•­")

            if result.has_circular_reference:
                lines.append(f"- âš ï¸ **ìˆœí™˜ ì°¸ì¡° ê°ì§€**: {len(result.circular_paths)}ê°œ")
                for path in result.circular_paths[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    lines.append(f"  - `{path}`")
                if len(result.circular_paths) > 5:
                    lines.append(f"  - ... ì™¸ {len(result.circular_paths) - 5}ê°œ")
            else:
                lines.append("- ğŸ”„ **ìˆœí™˜ ì°¸ì¡°**: ì—†ìŒ")

            if total_high > 0:
                lines.append(f"- âš ï¸ **High Risk** ë©”ì„œë“œ {total_high}ê°œ í¬í•¨")
                lines.append("  - ë³€ê²½ ì‹œ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ í•„ìš”")

            # íŒŒì¼ ì €ì¥
            with open(filepath, "w", encoding="utf-8") as f:
                f.write("\n".join(lines))

            logger.info(f"Markdown ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filepath}")
            return True

        except Exception as exc:
            logger.error(f"Markdown ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}", exc_info=True)
            return False

    def generate_excel(
        self,
        result: ImpactAnalysisResult,
        filepath: Path,
    ) -> bool:
        """Excel ë¦¬í¬íŠ¸ ìƒì„± (ë‹¤ì¤‘ ì‹œíŠ¸)

        Args:
            result: ImpactAnalysisResult ê°ì²´
            filepath: ì €ì¥ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            wb = Workbook()
            # ê¸°ë³¸ ì‹œíŠ¸ ì œê±°
            if "Sheet" in wb.sheetnames:
                wb.remove(wb["Sheet"])

            # ì‹œíŠ¸ ìƒì„±
            self._generate_summary_sheet(wb, result)
            self._generate_detail_sheet(wb, result)
            self._generate_package_sheet(wb, result)

            if result.sql_details:
                self._generate_sql_sheet(wb, result)

            if result.test_scope:
                self._generate_test_scope_sheet(wb, result)

            # íŒŒì¼ ì €ì¥
            wb.save(filepath)
            logger.info(f"Excel ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filepath}")
            return True

        except Exception as exc:
            logger.error(f"Excel ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}", exc_info=True)
            return False

    def _generate_summary_sheet(self, wb: Workbook, result: ImpactAnalysisResult):
        """Excel ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        ws = wb.create_sheet("Summary")

        # ìŠ¤íƒ€ì¼ ì •ì˜
        header_font = Font(bold=True, size=12)
        title_font = Font(bold=True, size=14)
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        border = Border(
            left=Side(style="thin"),
            right=Side(style="thin"),
            top=Side(style="thin"),
            bottom=Side(style="thin"),
        )

        # ì œëª©
        ws["A1"] = "ì˜í–¥ë„ ë¶„ì„ ìš”ì•½"
        ws["A1"].font = title_font

        # ë¶„ì„ ì •ë³´
        row = 3
        ws[f"A{row}"] = "ë¶„ì„ ëŒ€ìƒ"
        ws[f"B{row}"] = result.target_name
        ws[f"A{row}"].font = header_font

        row += 1
        ws[f"A{row}"] = "í”„ë¡œì íŠ¸"
        ws[f"B{row}"] = result.project_name or "ì „ì²´"

        row += 1
        ws[f"A{row}"] = "ë¶„ì„ ìœ í˜•"
        ws[f"B{row}"] = result.analysis_type

        row += 1
        ws[f"A{row}"] = "ë¶„ì„ ì¼ì‹œ"
        ws[f"B{row}"] = result.timestamp

        # ì˜í–¥ ë²”ìœ„
        row += 2
        ws[f"A{row}"] = "ì´ ì˜í–¥ ë²”ìœ„"
        ws[f"A{row}"].font = title_font

        row += 1
        ws[f"A{row}"] = "ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤"
        ws[f"B{row}"] = result.summary.total_impacted_classes

        row += 1
        ws[f"A{row}"] = "ì˜í–¥ë°›ëŠ” ë©”ì„œë“œ"
        ws[f"B{row}"] = result.summary.total_impacted_methods

        row += 1
        ws[f"A{row}"] = "ì˜í–¥ë°›ëŠ” íŒ¨í‚¤ì§€"
        ws[f"B{row}"] = result.summary.total_impacted_packages

        row += 1
        ws[f"A{row}"] = "ìµœëŒ€ í˜¸ì¶œ ê¹Šì´"
        ws[f"B{row}"] = result.summary.max_depth

        row += 1
        ws[f"A{row}"] = "í‰ê·  í˜¸ì¶œ ê¹Šì´"
        ws[f"B{row}"] = result.summary.avg_depth

        # ë¦¬ìŠ¤í¬ ë¶„í¬
        row += 2
        ws[f"A{row}"] = "ë¦¬ìŠ¤í¬ ë¶„í¬"
        ws[f"A{row}"].font = title_font

        row += 1
        ws[f"A{row}"] = "High"
        ws[f"B{row}"] = result.summary.risk_distribution.get("HIGH", 0)
        ws[f"B{row}"].font = Font(color="FF0000", bold=True)

        row += 1
        ws[f"A{row}"] = "Medium"
        ws[f"B{row}"] = result.summary.risk_distribution.get("MEDIUM", 0)
        ws[f"B{row}"].font = Font(color="FFA500", bold=True)

        row += 1
        ws[f"A{row}"] = "Low"
        ws[f"B{row}"] = result.summary.risk_distribution.get("LOW", 0)
        ws[f"B{row}"].font = Font(color="008000", bold=True)

        # ìˆœí™˜ ì°¸ì¡°
        if result.has_circular_reference:
            row += 2
            ws[f"A{row}"] = "ìˆœí™˜ ì°¸ì¡° ê°ì§€"
            ws[f"B{row}"] = f"{len(result.circular_paths)}ê°œ"
            ws[f"B{row}"].font = Font(color="FF0000", bold=True)

        # ì—´ ë„ˆë¹„ ì¡°ì •
        ws.column_dimensions["A"].width = 20
        ws.column_dimensions["B"].width = 30

    def _generate_detail_sheet(self, wb: Workbook, result: ImpactAnalysisResult):
        """Excel ìƒì„¸ ì‹œíŠ¸ ìƒì„±"""
        ws = wb.create_sheet("Impact Detail")

        # í—¤ë”
        headers = ["Level", "Depth", "Package", "Class", "Method", "SQL Type", "Complexity", "Risk", "ë¹„ê³ "]
        ws.append(headers)

        # í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")

        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(1, col_num)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center", vertical="center")

        # ë°ì´í„° ì¶”ê°€
        row_num = 2
        for level in sorted(result.impact_tree.keys()):
            nodes = result.impact_tree[level]
            for node in nodes:
                remark = "ì§ì ‘ ì‚¬ìš©" if level == 1 else f"{level-1}ì°¨ í˜¸ì¶œì"

                ws.cell(row_num, 1, level)
                ws.cell(row_num, 2, node.depth)
                ws.cell(row_num, 3, node.package_name)
                ws.cell(row_num, 4, node.class_name)
                ws.cell(row_num, 5, node.method_name)
                ws.cell(row_num, 6, node.sql_type or "")
                ws.cell(row_num, 7, node.sql_complexity or "")
                ws.cell(row_num, 8, node.risk_grade)
                ws.cell(row_num, 9, remark)

                # Risk ì…€ ìƒ‰ìƒ
                risk_cell = ws.cell(row_num, 8)
                if node.risk_grade == "HIGH":
                    risk_cell.font = Font(color="FF0000", bold=True)
                elif node.risk_grade == "MEDIUM":
                    risk_cell.font = Font(color="FFA500", bold=True)
                else:
                    risk_cell.font = Font(color="008000")

                row_num += 1

        # ì—´ ë„ˆë¹„ ì¡°ì •
        ws.column_dimensions["A"].width = 8
        ws.column_dimensions["B"].width = 8
        ws.column_dimensions["C"].width = 35
        ws.column_dimensions["D"].width = 25
        ws.column_dimensions["E"].width = 30
        ws.column_dimensions["F"].width = 12
        ws.column_dimensions["G"].width = 12
        ws.column_dimensions["H"].width = 10
        ws.column_dimensions["I"].width = 15

    def _generate_package_sheet(self, wb: Workbook, result: ImpactAnalysisResult):
        """Excel íŒ¨í‚¤ì§€ ì‹œíŠ¸ ìƒì„±"""
        ws = wb.create_sheet("Package Summary")

        # í—¤ë”
        headers = ["Package", "ì˜í–¥ í´ë˜ìŠ¤ ìˆ˜", "ì˜í–¥ ë©”ì„œë“œ ìˆ˜", "í‰ê·  Depth", "High", "Medium", "Low"]
        ws.append(headers)

        # í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")

        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(1, col_num)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center", vertical="center")

        # ë°ì´í„° ì¶”ê°€
        for row_num, pkg in enumerate(result.package_summary, 2):
            ws.cell(row_num, 1, pkg.package_name)
            ws.cell(row_num, 2, pkg.impacted_classes)
            ws.cell(row_num, 3, pkg.impacted_methods)
            ws.cell(row_num, 4, pkg.avg_depth)
            ws.cell(row_num, 5, pkg.risk_distribution.get("HIGH", 0))
            ws.cell(row_num, 6, pkg.risk_distribution.get("MEDIUM", 0))
            ws.cell(row_num, 7, pkg.risk_distribution.get("LOW", 0))

        # ì—´ ë„ˆë¹„ ì¡°ì •
        ws.column_dimensions["A"].width = 40
        ws.column_dimensions["B"].width = 15
        ws.column_dimensions["C"].width = 15
        ws.column_dimensions["D"].width = 12
        ws.column_dimensions["E"].width = 10
        ws.column_dimensions["F"].width = 10
        ws.column_dimensions["G"].width = 10

    def _generate_sql_sheet(self, wb: Workbook, result: ImpactAnalysisResult):
        """Excel SQL ìƒì„¸ ì‹œíŠ¸ ìƒì„±"""
        ws = wb.create_sheet("SQL Detail")

        # í—¤ë”
        headers = ["SQL ID", "SQL Type", "Mapper Class", "Mapper Method", "Complexity", "Query Preview"]
        ws.append(headers)

        # í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")

        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(1, col_num)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center", vertical="center")

        # ë°ì´í„° ì¶”ê°€
        for row_num, sql in enumerate(result.sql_details, 2):
            ws.cell(row_num, 1, sql.sql_id)
            ws.cell(row_num, 2, sql.sql_type)
            ws.cell(row_num, 3, sql.mapper_class)
            ws.cell(row_num, 4, sql.mapper_method)
            ws.cell(row_num, 5, sql.complexity)
            ws.cell(row_num, 6, sql.query_preview or "")

        # ì—´ ë„ˆë¹„ ì¡°ì •
        ws.column_dimensions["A"].width = 15
        ws.column_dimensions["B"].width = 12
        ws.column_dimensions["C"].width = 30
        ws.column_dimensions["D"].width = 30
        ws.column_dimensions["E"].width = 12
        ws.column_dimensions["F"].width = 50

    def _generate_test_scope_sheet(self, wb: Workbook, result: ImpactAnalysisResult):
        """Excel í…ŒìŠ¤íŠ¸ ë²”ìœ„ ì‹œíŠ¸ ìƒì„±"""
        ws = wb.create_sheet("Test Scope")

        # í—¤ë”
        headers = ["ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤", "ëŒ€ì‘ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤", "í…ŒìŠ¤íŠ¸ ë©”ì„œë“œ ìˆ˜", "ìƒíƒœ"]
        ws.append(headers)

        # í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")

        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(1, col_num)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center", vertical="center")

        # ë°ì´í„° ì¶”ê°€
        for row_num, item in enumerate(result.test_scope, 2):
            ws.cell(row_num, 1, item.impacted_class)
            ws.cell(row_num, 2, item.test_class or "N/A")
            ws.cell(row_num, 3, item.test_method_count)
            ws.cell(row_num, 4, item.status)

            # ìƒíƒœ ì…€ ìƒ‰ìƒ
            status_cell = ws.cell(row_num, 4)
            if item.status == "ì¡´ì¬":
                status_cell.font = Font(color="008000", bold=True)
            else:
                status_cell.font = Font(color="FF0000", bold=True)

        # ì—´ ë„ˆë¹„ ì¡°ì •
        ws.column_dimensions["A"].width = 35
        ws.column_dimensions["B"].width = 35
        ws.column_dimensions["C"].width = 18
        ws.column_dimensions["D"].width = 12

    def generate_json(
        self,
        result: ImpactAnalysisResult,
        filepath: Path,
    ) -> bool:
        """JSON ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            result: ImpactAnalysisResult ê°ì²´
            filepath: ì €ì¥ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # Pydantic ëª¨ë¸ì„ JSONìœ¼ë¡œ ì§ë ¬í™”
            data = result.model_dump(mode="json")

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            logger.info(f"JSON ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filepath}")
            return True

        except Exception as exc:
            logger.error(f"JSON ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}", exc_info=True)
            return False

    def generate_mermaid_diagram(
        self,
        result: ImpactAnalysisResult,
        filepath: Path,
    ) -> bool:
        """Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±

        Args:
            result: ImpactAnalysisResult ê°ì²´
            filepath: ì €ì¥ ê²½ë¡œ (.md)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            generator = ImpactMermaidGenerator()
            return generator.generate_diagram(result, filepath)

        except Exception as exc:
            logger.error(f"Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì‹¤íŒ¨: {exc}", exc_info=True)
            return False
