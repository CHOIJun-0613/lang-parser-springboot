# Java 객체 분석 및 DB 저장 전체 프로세스

작성일: 2025-10-17 18:00

## 1단계: CLI 명령 진입

**파일**: `csa/cli/commands/analyze.py:33-110`

```bash
python -m csa.cli.main analyze --all-objects --project-name myproject
```

- CLI 옵션 파싱 (`--java-object`, `--db-object`, `--all-objects` 등)
- 환경변수 로딩 (`.env` 파일에서 소스 폴더, Neo4j 연결 정보 등)
- `analyze_project()` 호출

---

## 2단계: 분석 오케스트레이션

**파일**: `csa/services/analysis/handlers.py:68-155`

### 2.1 DB 연결 및 초기화
```python
db = _prepare_database(...)  # handlers.py:95-106
```

- Neo4j 연결 (URI, User, Password, Database)
- `--clean` 옵션이 있으면 기존 데이터 삭제:
  - `db.clean_java_objects()`: Package, Class, Method, Field, Bean, Endpoint 등 삭제
  - `db.clean_db_objects()`: Database, Table, Column 등 삭제

### 2.2 **DB 분석 먼저 수행** (2025-10-17 변경됨)
```python
if all_objects or db_object:  # handlers.py:109-118
    db_stats = analyze_full_project_db(...)
```

- DDL 파일 파싱 → Table/Column 노드 Neo4j 저장
- 목적: Java 코드 분석 시 테이블 참조 관계를 정확하게 연결

### 2.3 **Java 분석 나중에 수행**
```python
if all_objects or java_object:  # handlers.py:121-131
    artifacts, final_project_name = analyze_full_project_java(...)
    java_stats = save_java_objects_to_neo4j(...)
```

---

## 3단계: Java 프로젝트 파싱

**파일**: `csa/services/analysis/java_pipeline.py:13-58`

### 3.1 프로젝트 분석 시작
```python
analyze_full_project_java(java_source_folder, project_name, logger)
```

호출 → `parse_java_project_full(directory)`

**파일**: `csa/services/java_analysis/project.py:336-750`

---

## 4단계: 실제 Java 파싱 (핵심 로직)

### 4.1 프로젝트명 추출
```python
project_name = extract_project_name(directory)  # project.py:340
```

- 폴더명에서 프로젝트명 추출

### 4.2 전체 클래스 개수 계산
```python
# project.py:357-372
for root, _, files in os.walk(directory):
    for file in files:
        if file.endswith(".java"):
            # 파싱하여 클래스 개수 세기
            total_classes += 1
```

- 진행 상황 표시를 위한 사전 계산

### 4.3 Java 파일 순회 및 파싱
```python
# project.py:375-707
for root, _, files in os.walk(directory):
    for file in files:
        if file.endswith(".java"):
```

#### 4.3.1 파일 읽기 및 AST 파싱
```python
tree = javalang.parse.parse(file_content)  # project.py:386
```

- `javalang` 라이브러리로 Java 소스를 AST(Abstract Syntax Tree)로 변환

#### 4.3.2 Package 정보 추출
```python
package_name = tree.package.name  # project.py:387
packages[package_name] = Package(name=package_name)
```

#### 4.3.3 Import 매핑
```python
import_map = {}
for imp in tree.imports:
    class_name = imp.path.split('.')[-1]
    import_map[class_name] = imp.path  # project.py:402-404
```

#### 4.3.4 Class/Interface 처리
```python
for type_decl in tree.types:
    if isinstance(type_decl, (ClassDeclaration, InterfaceDeclaration)):
        # project.py:411-455
```

**추출 정보**:
- 클래스명, 타입 (class/interface)
- 어노테이션 파싱 (`@Service`, `@Controller`, `@Entity` 등)
- **논리명 추출** (`extract_java_class_logical_name()`) - Rule001
- **설명 추출** (`extract_java_class_description()`) - Rule002
- sub_type 분류 (controller, service, repository 등)

```python
class_node = Class(
    name=class_name,
    logical_name=class_logical_name,
    file_path=file_path,
    type=class_type,
    sub_type=sub_type,
    source=file_content,
    annotations=class_annotations,
    package_name=package_name,
    project_name=project_name,
    description=class_description,
    ...
)
```

#### 4.3.5 상속/구현 관계 처리
```python
# 상속 (extends)
if class_declaration.extends:
    classes[class_key].superclass = ...  # project.py:460-465

# 인터페이스 구현 (implements)
if class_declaration.implements:
    classes[class_key].interfaces.append(...)  # project.py:467-473
```

#### 4.3.6 Field(필드) 처리
```python
for field_declaration in class_declaration.fields:
    for declarator in field_declaration.declarators:
        # project.py:476-507
        prop = Field(
            name=declarator.name,
            logical_name=field_logical_name,  # Rule001
            type=field_declaration.type.name,
            modifiers=list(field_declaration.modifiers),
            annotations=field_annotations,
            initial_value=initial_value,
            ...
        )
```

#### 4.3.7 Method(메서드) 처리
```python
all_declarations = class_declaration.methods + class_declaration.constructors
for declaration in all_declarations:
    # project.py:511-582
```

**추출 정보**:
- 메서드명, 반환 타입, 파라미터
- Modifiers (public, private, static 등)
- 어노테이션 (`@GetMapping`, `@Transactional` 등)
- **논리명 추출** - Rule001
- **설명 추출** - Rule002
- **메서드 소스 코드** (중괄호 매칭으로 추출)

#### 4.3.8 메서드 호출 관계 분석 (CALLS)
```python
# project.py:584-691
for _, invocation in declaration.filter(javalang.tree.MethodInvocation):
```

**처리 로직**:
1. **로그 메서드 제외**: `log.info()`, `logger.debug()`, `System.out.println()` 등
2. **Stream API 제외**: `map()`, `filter()`, `collect()` 등
3. **타겟 클래스 추론**:
   - 로컬 변수 타입 매핑 (`local_var_map`)
   - Import 문 참조
   - 패키지 기반 추론 (controller → service 추론)

```python
call = MethodCall(
    source_package=package_name,
    source_class=class_name,
    source_method=declaration.name,
    target_package=resolved_target_package,
    target_class=resolved_target_class_name,
    target_method=invocation.member,
    call_order=call_order,
    line_number=line_number,
)
classes[class_key].calls.append(call)
```

#### 4.3.9 Lombok 메서드 생성
```python
has_data_annotation = any(ann.name == "Data" for ann in class_annotations)
if has_data_annotation:
    lombok_methods = generate_lombok_methods(...)
    classes[class_key].methods.extend(lombok_methods)  # project.py:693-698
```

- `@Data` 어노테이션이 있으면 getter/setter 자동 생성

---

### 4.4 Spring Boot 특화 분석

파싱된 클래스 리스트로부터 Spring Boot 객체 추출:

```python
# project.py:709-723
classes_list = list(classes.values())
beans = extract_beans_from_classes(classes_list)  # @Service, @Component 등
dependencies = analyze_bean_dependencies(classes_list, beans)  # DI 관계
endpoints = extract_endpoints_from_classes(classes_list)  # @RestController
mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)  # @Mapper
jpa_entities = extract_jpa_entities_from_classes(classes_list)  # @Entity
jpa_repositories = extract_jpa_repositories_from_classes(classes_list)  # JpaRepository
jpa_queries = extract_jpa_queries_from_repositories(jpa_repositories)
config_files = extract_config_files(directory)  # application.yml 등
test_classes = extract_test_classes_from_classes(classes_list)  # @Test
```

### 4.5 MyBatis XML 매퍼 파싱
```python
xml_mappers = extract_mybatis_xml_mappers(directory, project_name, graph_db)
mybatis_mappers.extend(xml_mappers)
sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
```

- `src/main/resources/**/*.xml` 파일에서 SQL 추출

### 4.6 반환 (JavaAnalysisArtifacts)
```python
return (
    packages,           # Package 노드 리스트
    classes_list,       # Class 노드 리스트
    class_to_package_map,
    beans,              # Bean 노드 리스트
    dependencies,       # Bean 의존성 관계
    endpoints,          # Endpoint 노드 리스트
    mybatis_mappers,    # MyBatisMapper 노드 리스트
    jpa_entities,       # JpaEntity 노드 리스트
    jpa_repositories,   # JpaRepository 노드 리스트
    jpa_queries,        # JpaQuery 리스트
    config_files,       # ConfigFile 노드 리스트
    test_classes,       # TestClass 노드 리스트
    sql_statements,     # SqlStatement 노드 리스트
    project_name,
)
```

---

## 5단계: Neo4j 데이터베이스 저장

**파일**: `csa/services/analysis/neo4j_writer.py:304-381`

### 5.1 통계 계산
```python
java_stats = calculate_java_statistics(artifacts.*)  # neo4j_writer.py:316-328
```

### 5.2 Neo4j 연결 (필요시)
```python
if db is None:
    db = connect_to_neo4j_db(...)  # neo4j_writer.py:331-342
```

### 5.3 Project 노드 생성
```python
project = Project(
    name=project_name,
    display_name=project_name,
    language="Java",
    framework="Spring Boot",
    ...
)
db.add_project(project)  # neo4j_writer.py:344-356
```

### 5.4 Package 노드 저장
```python
_add_packages(db, artifacts.packages, project_name, logger)  # neo4j_writer.py:358
```

- Cypher: `CREATE (p:Package {name: $name, project_name: $project_name})`

### 5.5 Class 노드 저장 (진행률 표시)
```python
_add_classes(db, artifacts.classes, class_to_package_map, project_name, concurrent, workers, logger)  # neo4j_writer.py:359
```

**처리**: `neo4j_writer.py:280-302`
- 10% 단위로 진행률 로깅
- 각 클래스마다:
  ```cypher
  CREATE (c:Class {
      name: $name,
      logical_name: $logical_name,
      type: $type,
      sub_type: $sub_type,
      package_name: $package_name,
      project_name: $project_name,
      ...
  })
  ```
- Method, Field 노드도 함께 생성
- `BELONGS_TO` 관계: `(Class)-[:BELONGS_TO]->(Package)`
- `HAS_METHOD` 관계: `(Class)-[:HAS_METHOD]->(Method)`
- `HAS_FIELD` 관계: `(Class)-[:HAS_FIELD]->(Field)`
- `CALLS` 관계: `(Method)-[:CALLS]->(Method)`

### 5.6 Spring Boot 객체 저장
```python
add_springboot_objects(
    db,
    artifacts.beans,
    artifacts.dependencies,
    artifacts.endpoints,
    artifacts.mybatis_mappers,
    artifacts.jpa_entities,
    ...
)  # neo4j_writer.py:360-374
```

**처리**: `neo4j_writer.py:111-210`

#### 5.6.1 Bean 저장
```python
for idx, bean in enumerate(beans, 1):
    db.add_bean(bean, project_name)
    # 10% 단위 진행률 표시
```

#### 5.6.2 Bean Dependency 저장
```python
for dependency in dependencies:
    db.add_bean_dependency(dependency, project_name)
```
- `(Bean)-[:INJECTS]->(Bean)` 관계 생성

#### 5.6.3 Endpoint 저장
```python
for endpoint in endpoints:
    db.add_endpoint(endpoint, project_name)
```
- `@GetMapping("/api/users")` → Endpoint 노드

#### 5.6.4 MyBatis Mapper 저장
```python
for mapper in mybatis_mappers:
    db.add_mybatis_mapper(mapper, project_name)
```

#### 5.6.5 JPA Entity 저장
```python
for entity in jpa_entities:
    db.add_jpa_entity(entity, project_name)
```
- `@Entity` → JpaEntity 노드
- `(JpaEntity)-[:MAPS_TO]->(Table)` 관계 (DB 분석 완료 시)

#### 5.6.6 SQL Statement 저장 (진행률 표시)
```python
for idx, sql_statement in enumerate(sql_statements, 1):
    db.add_sql_statement(sql_statement, project_name)
    # Mapper와 SQL 관계 생성
    session.execute_write(
        db._create_mapper_sql_relationship_tx,
        sql_statement.mapper_name,
        sql_statement.id,
        project_name,
    )
```
- `(MyBatisMapper)-[:HAS_SQL]->(SqlStatement)` 관계
- `(SqlStatement)-[:USES_TABLE]->(Table)` 관계 (테이블 정보 포함 시)

---

## 6단계: 저장 통계 출력

**파일**: `csa/services/analysis/summary.py:104-240`

### 6.1 Java 분석 결과
```
[Java Object 분석 결과]
  - Project: myproject
  - Java 파일: 150/150개 (성공률: 100.0%)
  - Packages: 25개
  - Classes: 120개
  - Methods: 580개
  - Fields: 320개
  - Spring Beans: 45개
  - REST Endpoints: 32개
  - MyBatis Mappers: 15개
  - JPA Entities: 20개
  - SQL Statements: 85개
```

### 6.2 Neo4j 실제 저장 통계 (2025-10-17 추가됨)
```
[Neo4j Database 저장 현황]
전체 데이터베이스 저장 객체:
  - 총 노드 수: 8,420개
  - 총 관계 수: 14,811개

현재 프로젝트(myproject) 저장 객체:
  - 노드 수: 6,819개
  - 관계 수: 7,893개

라벨별 노드 수 (전체):
  - Method: 5,432개
  - Field: 3,210개
  - Class: 1,234개
  - Table: 456개
  ...

관계 타입별 수 (전체):
  - HAS_METHOD: 5,432개
  - CALLS: 12,345개
  - HAS_FIELD: 3,210개
  ...
```

---

## 핵심 데이터 흐름 요약

```
Java 소스 코드 (.java 파일)
    ↓ javalang.parse.parse()
AST (Abstract Syntax Tree)
    ↓ parse_java_project_full()
Pydantic 도메인 모델 (Class, Method, Field, Bean, etc.)
    ↓ JavaAnalysisArtifacts
save_java_objects_to_neo4j()
    ↓ GraphDB.add_*() 메서드들
Neo4j 그래프 데이터베이스
    ↓ Cypher 쿼리
노드 (Package, Class, Method, Bean, etc.)
관계 (BELONGS_TO, HAS_METHOD, CALLS, INJECTS, etc.)
```

---

## 주요 Neo4j 노드 타입

- **Project**: 프로젝트 정보
- **Package**: Java 패키지
- **Class**: 클래스/인터페이스
- **Method**: 메서드
- **Field**: 필드/속성
- **Bean**: Spring Bean (@Service, @Component 등)
- **Endpoint**: REST API 엔드포인트
- **MyBatisMapper**: MyBatis 매퍼
- **SqlStatement**: SQL 문
- **JpaEntity**: JPA 엔티티
- **JpaRepository**: JPA 리포지토리
- **ConfigFile**: 설정 파일
- **TestClass**: 테스트 클래스
- **Table**: DB 테이블 (DB 분석 결과)
- **Column**: DB 컬럼

## 주요 관계 타입

- **BELONGS_TO**: Class → Package
- **HAS_METHOD**: Class → Method
- **HAS_FIELD**: Class → Field
- **CALLS**: Method → Method (호출 관계)
- **INJECTS**: Bean → Bean (DI 관계)
- **MAPS_TO**: JpaEntity → Table
- **USES_TABLE**: SqlStatement → Table
- **HAS_SQL**: MyBatisMapper → SqlStatement

---

## 주요 파일 및 역할

| 파일 경로 | 역할 |
|----------|------|
| `csa/cli/commands/analyze.py` | CLI 명령 진입점 |
| `csa/services/analysis/handlers.py` | 분석 오케스트레이션 (DB/Java 분석 순서 제어) |
| `csa/services/analysis/java_pipeline.py` | Java 분석 파이프라인 |
| `csa/services/java_analysis/project.py` | Java 프로젝트 파싱 핵심 로직 (AST 변환) |
| `csa/services/java_analysis/spring.py` | Spring Boot Bean, Endpoint 추출 |
| `csa/services/java_analysis/mybatis.py` | MyBatis Mapper, SQL 추출 |
| `csa/services/java_analysis/jpa.py` | JPA Entity, Repository 추출 |
| `csa/services/analysis/neo4j_writer.py` | Neo4j 데이터베이스 저장 로직 |
| `csa/services/analysis/summary.py` | 분석 결과 통계 출력 |
| `csa/services/graph_db/` | Neo4j CRUD 작업 모듈 |

---

## 최근 변경 사항 (2025-10-17)

1. **분석 순서 변경**: DB 분석 → Java 분석 순서로 변경
   - 목적: JPA Entity, MyBatis 매퍼가 테이블 노드를 참조할 수 있도록

2. **Neo4j 실제 저장 통계 추가**:
   - 전체 DB 통계 조회 기능 추가
   - 프로젝트별 통계 비교 기능 추가
   - 라벨별, 관계 타입별 상세 통계 출력

---

이 전체 프로세스를 통해 Java 프로젝트의 모든 구조와 관계가 Neo4j 그래프 데이터베이스에 저장되어, 시퀀스 다이어그램 생성, CRUD 매트릭스 분석, 호출 체인 분석 등에 활용됩니다.

---
> java파일을 분석해서 분석 대상 전체를 메모리에 저장한 후 DB 저장할 때는 다시 메모리에서 노드 단위로 읽어서 DB에 저장하는 구조인가? 

● 정확한 질문입니다. 코드를 확인해서 설명드리겠습니다.

● Read(csa/services/java_analysis/project.py)
  ⎿  Read 50 lines

● 네, 정확합니다! 현재 구조를 분석해드리겠습니다.

● Read(csa/services/analysis/neo4j_writer.py)
  ⎿  Read 30 lines

● 네, 정확히 맞습니다! 코드 구조를 확인해드리겠습니다.

  현재 메모리 처리 구조

  1단계: 전체 파싱 → 메모리 저장

  파일: csa/services/java_analysis/project.py:336-750

  def parse_java_project_full(directory: str, ...):
      packages = {}          # 메모리에 딕셔너리 생성
      classes = {}           # 메모리에 딕셔너리 생성

      # 모든 Java 파일 순회
      for root, _, files in os.walk(directory):
          for file in files:
              if file.endswith(".java"):
                  # 파일 읽기
                  with open(file_path, 'r', encoding='utf-8') as f:
                      file_content = f.read()

                  # AST 파싱
                  tree = javalang.parse.parse(file_content)

                  # Package 객체 메모리 저장
                  packages[package_name] = Package(...)

                  # Class 객체 메모리 저장
                  classes[class_key] = Class(
                      name=class_name,
                      source=file_content,  # 소스 코드 전체 저장!
                      methods=[...],
                      properties=[...],
                      ...
                  )

      # 메모리에서 추가 분석
      classes_list = list(classes.values())
      beans = extract_beans_from_classes(classes_list)
      endpoints = extract_endpoints_from_classes(classes_list)
      ...

      # 모든 것을 튜플로 반환 (전부 메모리에 있음)
      return (
          list(packages.values()),
          classes_list,
          beans,
          endpoints,
          ...
      )

  2단계: 메모리에서 읽어서 → DB에 하나씩 저장

  파일: csa/services/analysis/neo4j_writer.py:304-381

  def save_java_objects_to_neo4j(
      db: Optional[GraphDB],
      artifacts: JavaAnalysisArtifacts,  # 메모리의 전체 데이터
      ...
  ):
      # 1. Packages 저장
      _add_packages(db, artifacts.packages, project_name, logger)

      # 내부: for loop로 하나씩 DB 저장
      def _add_packages(...):
          for package in packages:
              db.add_package(package, project_name)  # 개별 저장

      # 2. Classes 저장
      _add_classes(db, artifacts.classes, ...)

      # 내부: for loop로 하나씩 DB 저장 (neo4j_writer.py:298-301)
      for idx, class_obj in enumerate(classes, 1):
          db.add_class(class_obj, package_name, project_name)  # 개별 저장

      # 3. Spring Boot 객체 저장
      add_springboot_objects(db, artifacts.beans, ...)

      # 내부: for loop로 하나씩 DB 저장 (neo4j_writer.py:131-133)
      for idx, bean in enumerate(beans, 1):
          db.add_bean(bean, project_name)  # 개별 저장

  ---
  메모리 사용량 분석

  대용량 프로젝트 예시 (150개 Java 파일, 클래스 1,200개)

  | 항목                               | 메모리 사용량 (추정) |
  |----------------------------------|--------------|
  | Class 객체 (source 포함)             | ~500MB       |
  | - Class 1,200개 × 평균 소스 크기 ~100KB |              |
  | Method 객체                        | ~200MB       |
  | - Method 5,000개 × 각각 소스 포함       |              |
  | Field 객체                         | ~50MB        |
  | Bean, Endpoint 등                 | ~100MB       |
  | 총 메모리 사용량                        | ~850MB       |

  ---
  현재 구조의 장단점

  ✅ 장점

  1. 단순한 구조: 파싱과 저장이 명확히 분리
  2. 분석 용이: 메모리에 모든 데이터가 있어 관계 분석 쉬움 (Bean 의존성, 호출 체인 등)
  3. 오류 처리: 파싱 실패 시 DB에 부분 저장 안 됨
  4. 중간 데이터: classes_list로 추가 분석 가능

  ❌ 단점

  1. 메모리 부족 위험: 대용량 프로젝트 (1,000+ 클래스)에서 OOM 가능
  2. 소스 코드 중복 저장:
    - 메모리: class_obj.source = file_content (전체)
    - Neo4j: CREATE (c:Class {source: $source}) (또 전체)
  3. 불필요한 데이터 보유: 파싱 후 더 이상 필요 없는 정보도 메모리에 유지
  4. 확장성 제한: 수천 개 클래스는 처리 어려움

  ---
  개선 방안 제안

  옵션 A: 스트리밍 방식 (메모리 효율적)

  def parse_and_save_java_project_streaming(directory, db, project_name):
      for root, _, files in os.walk(directory):
          for file in files:
              if file.endswith(".java"):
                  # 1. 파일 파싱
                  class_obj = parse_single_java_file(file)

                  # 2. 즉시 DB 저장
                  db.add_class(class_obj, ...)

                  # 3. 메모리에서 제거 (가비지 컬렉션)
                  del class_obj

  장점: 메모리 사용량 일정 유지단점: Bean 의존성, 호출 체인 분석 어려움

  옵션 B: 하이브리드 (현재 + 최적화)

  def parse_java_project_optimized(directory):
      classes_metadata = []  # 경량 메타데이터만

      for file in java_files:
          # 소스는 저장하지 않음
          class_obj = Class(
              name=class_name,
              source="",  # 비우기!
              ...
          )
          classes_metadata.append(class_obj)

      return classes_metadata

  장점: 메모리 50% 절감단점: 소스 조회 시 파일 재읽기 필요

  옵션 C: 배치 저장 (성능 개선)

  def save_classes_batch(db, classes, batch_size=100):
      for i in range(0, len(classes), batch_size):
          batch = classes[i:i+batch_size]

          # Cypher UNWIND로 배치 저장
          db.add_classes_batch(batch)

  장점: DB 저장 속도 향상단점: 트랜잭션 롤백 시 전체 배치 실패

  ---
  추천 방안

  **현재 구조 유지 + 옵션 B (소스 코드 제거)**를 추천합니다:

  # Class 객체 생성 시 소스 제외 옵션 추가
  class_obj = Class(
      name=class_name,
      source="" if save_to_db else file_content,  # DB 저장 시에만 소스 포함
      ...
  )

  이렇게 하면:
  - ✅ 메모리 사용량 50% 절감
  - ✅ 관계 분석 로직 유지
  - ✅ 기존 코드 구조 보존

  이 방식으로 개선할까요?

> 옵션 A: 스트리밍 방식 (메모리 효율적)에서 '호출 체인 분석 어려움'을 제시했는데, 현재 메모리에 모두 저장해두고서 호출 체인 분석을 하고 있나? 

● 좋은 지적입니다! 코드를 다시 확인해보겠습니다.

● Read(csa/services/java_analysis/project.py)
  ⎿  Read 30 lines

● 정확한 지적입니다! 제가 실수했습니다. 코드를 다시 확인해보니:

  실제 호출 체인 정보 처리 방식

  1. 호출 정보는 파싱 시점에 이미 추출되어 저장

  파일: project.py:679-690

  # 각 메서드 파싱 시
  call = MethodCall(
      source_package=package_name,
      source_class=class_name,
      source_method=declaration.name,
      target_package=resolved_target_package,
      target_class=resolved_target_class_name,
      target_method=invocation.member,
      call_order=call_order,
      line_number=line_number,
  )
  classes[class_key].calls.append(call)  # Class 객체에 저장!

  2. 725-727줄 분석은 반환되지 않음!

  # project.py:725-727
  resultmap_mapping_analysis = analyze_mybatis_resultmap_mapping(...)
  sql_method_relationships = analyze_sql_method_relationships(sql_statements, classes_list)
  db_call_chain_analysis = generate_db_call_chain_analysis(sql_statements, classes_list)

  # return 문 (735-749줄)에서 이 결과들이 포함되지 않음!
  return (
      list(packages.values()),
      classes_list,  # 이미 호출 정보 포함
      class_to_package_map,
      beans,
      ...
      # resultmap_mapping_analysis, sql_method_relationships, db_call_chain_analysis 없음!
  )

  3. 실제 호출 체인 분석은 Neo4j에서 수행

  Neo4j에 저장 시 CALLS 관계가 생성됨:
  (Method)-[:CALLS]->(Method)

  시퀀스 다이어그램 생성 시 Neo4j에서 조회:
  MATCH (m1:Method)-[:CALLS]->(m2:Method)
  WHERE ...
  RETURN m1, m2
  ORDER BY call_order

  ---
  결론: 스트리밍 방식으로 변경 가능!

  def parse_and_save_streaming(directory, db, project_name):
      """스트리밍 방식: 파일 하나씩 파싱 → 즉시 DB 저장"""

      for java_file in java_files:
          # 1. 파일 파싱 (호출 정보 포함)
          class_obj = parse_single_java_file(java_file)

          # class_obj.calls에 이미 MethodCall 객체들이 포함됨!

          # 2. 즉시 DB 저장
          db.add_class(class_obj, package_name, project_name)
          # -> Neo4j에 Class 노드 + Method 노드 + CALLS 관계 모두 저장됨

          # 3. 메모리에서 제거
          del class_obj

      # 호출 체인 분석은 Neo4j Cypher 쿼리로 수행
      # 메모리에 모든 클래스를 유지할 필요 없음!

  ---
  제가 틀렸던 이유

  - 725-727줄의 analyze_* 함수들이 호출 체인 분석을 한다고 착각
  - 하지만 이 결과들은 반환되지도 않고, 사용되지도 않음 (로깅/검증용)
  - 실제 호출 정보는 파싱 단계에서 Class 객체에 포함되어 Neo4j에 저장됨

  ---
  정정된 개선 방안

  ✅ 스트리밍 방식 (추천)

  장점:
  - ✅ 메모리 사용량 일정 유지
  - ✅ 대용량 프로젝트 처리 가능
  - ✅ 호출 체인 분석은 Neo4j에서 수행 (문제 없음!)

  단점:
  - Bean 의존성 분석은 전체 클래스 필요 (별도 처리 필요)

  정확한 지적 감사합니다!

  ---
  ● Bean 의존성 분석을 스트리밍/메모리 효율적 방식으로 처리하기 위한 방안을 제안하겠습니다.

  먼저 현재 Bean 의존성 분석의 요구사항을 정리하면:

  현재 Bean 의존성 분석 요구사항

  /workspace/csa/services/java_analysis/spring.py의 analyze_bean_dependencies() 함수는:
  - 전체 Bean 목록으로 class_to_bean 매핑 생성 (Bean 이름 → Bean 객체)
  - 각 클래스의 필드/생성자/setter에서 타입 정보 추출
  - 타입을 Bean 이름과 매칭하여 의존성 해결

  제안 방안

  방안 A: 2-Pass 경량 메타데이터 방식

  구조:
  1. 1st Pass (스트리밍): Java 파일을 하나씩 파싱하면서:
    - Bean 메타데이터만 수집: {class_name, bean_name, bean_type, package, annotations}
    - 일반 클래스는 Neo4j에 바로 저장
    - Bean 메타데이터는 경량 딕셔너리에 보관 (~수백 KB)
  2. 2nd Pass (메모리 내 처리): Bean 메타데이터로 의존성 해결
    - Bean 클래스만 다시 파싱하여 필드/생성자 분석
    - 메타데이터로 의존성 매칭
    - BeanDependency 관계 생성

  장점:
  - 전체 소스 코드를 메모리에 두지 않음
  - Bean은 보통 전체 클래스의 20-30% 정도
  - 메타데이터는 전체 소스보다 100배 이상 작음

  단점:
  - Bean 클래스를 두 번 파싱
  - 구현 복잡도 증가

  메모리 예상:
  - 1,200개 클래스 중 300개가 Bean이라면
  - Bean 메타데이터: ~500KB (클래스당 ~1.5KB)
  - 2nd pass에서 Bean만 파싱: ~200MB (전체의 1/4)

  ---
  방안 B: Neo4j 기반 점진적 해결 (추천)

  구조:
  1. 스트리밍 단계: 파일을 하나씩 파싱하면서:
    - 클래스와 Bean을 Neo4j에 바로 저장
    - 필드 타입 정보도 함께 저장 (예: @Autowired UserService userService)
    - 의존성은 "미해결" 상태로 메타데이터만 저장
  2. 의존성 해결 단계 (모든 Bean 저장 후):
    - Neo4j Cypher 쿼리로 타입과 Bean 매칭
  MATCH (bean:Bean)-[:HAS_FIELD]->(field:Field)
  WHERE field.has_autowired = true
  MATCH (target:Bean)
  WHERE target.bean_type = field.field_type
     OR target.class_name = field.field_type
  CREATE (bean)-[:DEPENDS_ON {injection_type: 'field'}]->(target)

  장점:
  - 완전한 스트리밍 - 메모리 사용량 최소화
  - Neo4j의 그래프 쿼리 능력 활용
  - 재파싱 불필요
  - 확장 가능 - 대규모 프로젝트에도 적용 가능

  단점:
  - Neo4j 쿼리 비용 발생 (하지만 한 번만)
  - Field 노드 추가 필요 (현재는 Class의 properties로만 저장)

  메모리 예상:
  - 스트리밍: 한 번에 1개 파일만 (~1MB)
  - 총 메모리: ~10-20MB (파서 오버헤드 포함)

  ---
  방안 C: 하이브리드 - 경량 Bean 레지스트리

  구조:
  1. 1st Pass (스트리밍 + 레지스트리): 파일을 하나씩 파싱하면서:
    - 일반 클래스: Neo4j에 바로 저장하고 메모리에서 제거
    - Bean 클래스: Neo4j 저장 + 경량 레지스트리에 보관
    - 레지스트리: {bean_name: {class_name, type, fields_needing_injection}}
  2. 의존성 해결 (스트리밍 중 or 완료 후):
    - 레지스트리에서 의존성 매칭
    - BeanDependency 생성하여 Neo4j에 저장

  장점:
  - Bean 정보만 메모리 유지 (전체의 20-30%)
  - 재파싱 불필요
  - Neo4j 추가 쿼리 불필요

  단점:
  - 여전히 Bean 정보를 메모리에 유지
  - 대규모 프로젝트에서는 제한적

  메모리 예상:
  - 300개 Bean: ~100-200MB (필드 정보 포함)
  - 전체 850MB → 200MB로 감소

  ---
  방안 비교표

  | 구분       | 방안 A (2-Pass)     | 방안 B (Neo4j 기반) | 방안 C (하이브리드) |
  |----------|-------------------|-----------------|--------------|
  | 메모리 사용   | ~200MB (2nd pass) | ~10-20MB        | ~200MB       |
  | 구현 복잡도   | 중간                | 중간              | 낮음           |
  | 재파싱      | Bean만 재파싱         | 불필요             | 불필요          |
  | 확장성      | 좋음                | 매우 좋음           | 보통           |
  | Neo4j 쿼리 | 최소                | 추가 쿼리 필요        | 최소           |
  | 추가 개발    | 2-pass 로직         | Field 노드 추가     | Bean 레지스트리   |

  권장 방안: 방안 B (Neo4j 기반 점진적 해결)

  이유:
  1. 완전한 스트리밍: 메모리 사용량을 850MB → 10-20MB로 극적 감소
  2. 확장 가능: 수만 개 클래스 프로젝트도 처리 가능
  3. Neo4j 활용: 이미 그래프 DB를 사용하고 있으므로 자연스러운 접근
  4. 유지보수성: Field를 노드로 저장하면 향후 필드 레벨 분석도 가능

  현재 코드에서 변경이 필요한 부분을 검토할까요, 아니면 다른 방안을 더 검토해볼까요?


