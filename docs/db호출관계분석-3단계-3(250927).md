# ê²°ê³¼ ì¶œë ¥ ë¬¸ì œ í•´ê²°
_Exported on 9/27/2025 at 20:00:43 GMT+9 from Cursor (1.6.45)_

---

**User**

ê²°ê³¼ê°€ ì •ìƒì ìœ¼ë¡œ ì¶œë ¥ë˜ì§€ ì•Šì•˜ì–´...

---

**Cursor**

í„°ë¯¸ë„ ì¶œë ¥ì„ ë³´ë‹ˆ CRUD ë¶„ì„ ê²°ê³¼ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë„¤ìš”. ë‘ ê°€ì§€ ì£¼ìš” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤:

1. **Neo4j ê´€ê³„ íƒ€ì… ì˜¤ë¥˜**: `USES_TABLE` ê´€ê³„ íƒ€ì…ì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²½ê³ 
2. **CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜**: `unsupported format string passed to NoneType.__format__` ì˜¤ë¥˜

ë¨¼ì € í˜„ì¬ ì½”ë“œë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ë” ìì„¸íˆ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ CLI ë¶€ë¶„ì˜ ì¶œë ¥ ì½”ë“œë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ë¬¸ì œë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤. ë‘ ê°€ì§€ ì£¼ìš” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤:

1. **USES_TABLE ê´€ê³„ íƒ€ì…ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ**: Neo4j ì¿¼ë¦¬ì—ì„œ `USES_TABLE` ê´€ê³„ë¥¼ ì°¾ê³  ìˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ì´ ê´€ê³„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
2. **Format string ì˜¤ë¥˜**: `operations` ë³€ìˆ˜ê°€ `None`ì¼ ë•Œ format stringì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

ì´ ë¬¸ì œë“¤ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € `USES_TABLE` ê´€ê³„ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = row.get('database_name', 'default')
                    schema_name = row.get('schema_name', 'public')
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}

```

ì´ì œ ë°ì´í„° ì²˜ë¦¬ ë¶€ë¶„ì—ì„œ `database_name`ê³¼ `schema_name`ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}

```

ì´ì œ CLI ë¶€ë¶„ì˜ format string ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        result = analysis_service.generate_crud_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        class_matrix = result['class_matrix']
        table_matrix = result['table_matrix']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # í´ë˜ìŠ¤ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (1:1 ê´€ê³„ë¡œ í‘œì‹œ, database/schema í¬í•¨)
        if class_matrix:
            click.echo(f"\nClass CRUD Matrix:")
            click.echo("-" * 130)
            click.echo(f"{'Class Name':<30} {'Package':<35} {'Database':<15} {'Schema':<10} {'Table':<20} {'Operations':<15}")
            click.echo("-" * 130)
            
            for row in class_matrix:
                class_name = row['class_name']
                package_name = row['package_name'] or 'N/A'
                
                # ê° í…Œì´ë¸”ë³„ë¡œ ë³„ë„ í–‰ìœ¼ë¡œ í‘œì‹œ
                if isinstance(row['tables'], list) and row['tables']:
                    for table_info in row['tables']:
                        if isinstance(table_info, dict):
                            table_name = table_info.get('table_name', 'Unknown')
                            database_name = table_info.get('database_name', 'default')
                            schema_name = table_info.get('schema_name', 'public')
                            operations_list = table_info.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        else:
                            table_name = str(table_info)
                            database_name = 'default'
                            schema_name = 'public'
                            operations_list = row.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        
                        click.echo(f"{class_name:<30} {package_name:<35} {database_name:<15} {schema_name:<10} {table_name:<20} {operations:<15}")
                else:
                    # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
                    tables = ', '.join(row['tables']) if row['tables'] else 'None'
                    operations = ', '.join(row['operations']) if row['operations'] else 'None'
                    click.echo(f"{class_name:<30} {package_name:<35} {'default':<15} {'public':<10} {tables:<20} {operations:<15}")
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤
        if table_matrix:
            click.echo(f"\nTable CRUD Matrix:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Operations':<30}")
            click.echo("-" * 60)
            
            for row in table_matrix:
                table_name = row['table_name']
                operations = []
                for op in row['operations']:
                    operations.append(f"{op['operation']}({op['count']})")
                operations_str = ', '.join(operations)
                
                click.echo(f"{table_name:<30} {operations_str:<30}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ê¸°ì¡´ ë°©ì‹ ë¶€ë¶„ë„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        result = analysis_service.generate_crud_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        class_matrix = result['class_matrix']
        table_matrix = result['table_matrix']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # í´ë˜ìŠ¤ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (1:1 ê´€ê³„ë¡œ í‘œì‹œ, database/schema í¬í•¨)
        if class_matrix:
            click.echo(f"\nClass CRUD Matrix:")
            click.echo("-" * 130)
            click.echo(f"{'Class Name':<30} {'Package':<35} {'Database':<15} {'Schema':<10} {'Table':<20} {'Operations':<15}")
            click.echo("-" * 130)
            
            for row in class_matrix:
                class_name = row['class_name']
                package_name = row['package_name'] or 'N/A'
                
                # ê° í…Œì´ë¸”ë³„ë¡œ ë³„ë„ í–‰ìœ¼ë¡œ í‘œì‹œ
                if isinstance(row['tables'], list) and row['tables']:
                    for table_info in row['tables']:
                        if isinstance(table_info, dict):
                            table_name = table_info.get('table_name', 'Unknown')
                            database_name = table_info.get('database_name', 'default')
                            schema_name = table_info.get('schema_name', 'public')
                            operations_list = table_info.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        else:
                            table_name = str(table_info)
                            database_name = 'default'
                            schema_name = 'public'
                            operations_list = row.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        
                        click.echo(f"{class_name:<30} {package_name:<35} {database_name:<15} {schema_name:<10} {table_name:<20} {operations:<15}")
                else:
                    # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
                    tables_list = row.get('tables', [])
                    tables = ', '.join(tables_list) if tables_list else 'None'
                    operations_list = row.get('operations', [])
                    operations = ', '.join(operations_list) if operations_list else 'None'
                    click.echo(f"{class_name:<30} {package_name:<35} {'default':<15} {'public':<10} {tables:<20} {operations:<15}")
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤
        if table_matrix:
            click.echo(f"\nTable CRUD Matrix:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Operations':<30}")
            click.echo("-" * 60)
            
            for row in table_matrix:
                table_name = row['table_name']
                operations = []
                for op in row['operations']:
                    operations.append(f"{op['operation']}({op['count']})")
                operations_str = ', '.join(operations)
                
                click.echo(f"{table_name:<30} {operations_str:<30}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ ìˆ˜ì •ëœ ì½”ë“œë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! ì´ì œ CRUD ë¶„ì„ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. 

## ìˆ˜ì •ëœ ë‚´ìš© ìš”ì•½:

1. **USES_TABLE ê´€ê³„ íƒ€ì… ì˜¤ë¥˜ í•´ê²°**: 
   - Neo4j ì¿¼ë¦¬ì—ì„œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” `USES_TABLE` ê´€ê³„ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.
   - `OPTIONAL MATCH` ë¶€ë¶„ì„ ì œê±°í•˜ê³  í…Œì´ë¸” ì •ë³´ë¥¼ ì§ì ‘ íŒŒì‹±í•˜ë„ë¡ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.

2. **Format string ì˜¤ë¥˜ í•´ê²°**:
   - `operations` ë³€ìˆ˜ê°€ `None`ì¼ ë•Œ ë°œìƒí•˜ëŠ” format string ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
   - `None` ê°’ì— ëŒ€í•œ ì•ˆì „í•œ ì²˜ë¦¬ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

## ê²°ê³¼:

ì´ì œ CRUD ë¶„ì„ì´ ì •ìƒì ìœ¼ë¡œ ì¶œë ¥ë˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

- **CRUD Summary**: ì „ì²´ í†µê³„ (í´ë˜ìŠ¤ ìˆ˜, í…Œì´ë¸” ìˆ˜, ê° CRUD ì—°ì‚° ìˆ˜)
- **Class CRUD Matrix**: í´ë˜ìŠ¤ë³„ë¡œ ì–´ë–¤ í…Œì´ë¸”ì— ì–´ë–¤ CRUD ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ í‘œì‹œ
- **Table CRUD Matrix**: í…Œì´ë¸”ë³„ë¡œ ê° CRUD ì—°ì‚°ì´ ëª‡ ë²ˆ ìˆ˜í–‰ë˜ëŠ”ì§€ í‘œì‹œ

ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ë©´ `car-center-devlab` í”„ë¡œì íŠ¸ì—ì„œ 15ê°œì˜ í´ë˜ìŠ¤ê°€ 15ê°œì˜ í…Œì´ë¸”ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©°, ê°ì¢… CRUD ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**User**

**3ë‹¨ê³„: ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ì‹œê°í™” ê¸°ëŠ¥ êµ¬í˜„**
-  í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
ì§„í–‰í•´ì¤˜

---

**Cursor**

3ë‹¨ê³„ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ì‹œê°í™” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤. Mermaid ë‹¤ì´ì–´ê·¸ë¨ì„ ì‚¬ìš©í•´ì„œ í˜¸ì¶œ ê´€ê³„ë¥¼ ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € í˜„ì¬ ì‹œê°í™” ê¸°ëŠ¥ì´ ì–´ë–»ê²Œ êµ¬í˜„ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ê¸°ì¡´ ì‹œê°í™” ê¸°ëŠ¥ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ CLIì—ì„œ ê¸°ì¡´ ì‹œê°í™” ëª…ë ¹ì–´ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ê¸°ì¡´ CLI ëª…ë ¹ì–´ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ì‹œê°í™”ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤. CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.


`DBCallAnalysisService`ì— CRUD ë§¤íŠ¸ë¦­ìŠ¤ ê¸°ë°˜ ì‹œê°í™” ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
        return {
            'class_matrix': class_matrix,
            'table_matrix': table_matrix,
            'summary': summary
        }
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]:::class")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
```

íŒŒì¼ì˜ ë ë¶€ë¶„ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


íŒŒì¼ì˜ ë ë¶€ë¶„ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


íŒŒì¼ì˜ ëì— ìƒˆë¡œìš´ ë©”ì„œë“œë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]:::class")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"

```

ì´ì œ CLIì— ìƒˆë¡œìš´ ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


CLIì— ìƒˆë¡œìš´ ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. ê¸°ì¡´ `db_call_diagram` ëª…ë ¹ì–´ ë‹¤ìŒì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


ìƒˆë¡œìš´ CLI ëª…ë ¹ì–´ë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. `table_impact` ëª…ë ¹ì–´ ì•ì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        result = analysis_service.generate_crud_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        class_matrix = result['class_matrix']
        table_matrix = result['table_matrix']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # í´ë˜ìŠ¤ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (1:1 ê´€ê³„ë¡œ í‘œì‹œ, database/schema í¬í•¨)
        if class_matrix:
            click.echo(f"\nClass CRUD Matrix:")
            click.echo("-" * 130)
            click.echo(f"{'Class Name':<30} {'Package':<35} {'Database':<15} {'Schema':<10} {'Table':<20} {'Operations':<15}")
            click.echo("-" * 130)
            
            for row in class_matrix:
                class_name = row['class_name']
                package_name = row['package_name'] or 'N/A'
                
                # ê° í…Œì´ë¸”ë³„ë¡œ ë³„ë„ í–‰ìœ¼ë¡œ í‘œì‹œ
                if isinstance(row['tables'], list) and row['tables']:
                    for table_info in row['tables']:
                        if isinstance(table_info, dict):
                            table_name = table_info.get('table_name', 'Unknown')
                            database_name = table_info.get('database_name', 'default')
                            schema_name = table_info.get('schema_name', 'public')
                            operations_list = table_info.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        else:
                            table_name = str(table_info)
                            database_name = 'default'
                            schema_name = 'public'
                            operations_list = row.get('operations', [])
                            operations = ', '.join(operations_list) if operations_list else 'None'
                        
                        click.echo(f"{class_name:<30} {package_name:<35} {database_name:<15} {schema_name:<10} {table_name:<20} {operations:<15}")
                else:
                    # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
                    tables_list = row.get('tables', [])
                    tables = ', '.join(tables_list) if tables_list else 'None'
                    operations_list = row.get('operations', [])
                    operations = ', '.join(operations_list) if operations_list else 'None'
                    click.echo(f"{class_name:<30} {package_name:<35} {'default':<15} {'public':<10} {tables:<20} {operations:<15}")
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤
        if table_matrix:
            click.echo(f"\nTable CRUD Matrix:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Operations':<30}")
            click.echo("-" * 60)
            
            for row in table_matrix:
                table_name = row['table_name']
                operations = []
                for op in row['operations']:
                    operations.append(f"{op['operation']}({op['count']})")
                operations_str = ', '.join(operations)
                
                click.echo(f"{table_name:<30} {operations_str:<30}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ ìƒˆë¡œìš´ ì‹œê°í™” ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ìƒˆë¡œìš´ ì‹œê°í™” ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! ì‹œê°í™” ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ìƒì„±ëœ ë‹¤ì´ì–´ê·¸ë¨ íŒŒì¼ë„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ ì´ë¯¸ì§€ë¡œë„ ë³€í™˜í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ë¯¸ì§€ ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ë¯¸ì§€ ë³€í™˜ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. mermaid-cliê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


mermaid-cliê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´ë¯¸ì§€ ë³€í™˜ì„ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤.


Mermaid íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. `:::class`ì™€ `:::table` ë¬¸ë²•ì´ ë¬¸ì œì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ë²•ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"

```

ìŠ¤íƒ€ì¼ ì •ì˜ë„ ì œê±°í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"

```

ì´ì œ ìˆ˜ì •ëœ ì‹œê°í™” ê¸°ëŠ¥ì„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! ì´ë¯¸ì§€ ë³€í™˜ì´ ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ìƒì„±ëœ íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! **3ë‹¨ê³„: ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ì‹œê°í™” ê¸°ëŠ¥**ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

## êµ¬í˜„ëœ ê¸°ëŠ¥ ìš”ì•½:

### 1. **CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ê¸°ëŠ¥**
- `DBCallAnalysisService.generate_crud_visualization_diagram()` ë©”ì„œë“œ ì¶”ê°€
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì‹œê°í™”
- ê° ì—°ê²°ì„ ì— CRUD ì—°ì‚° ì •ë³´ í‘œì‹œ (C, R, U, D)

### 2. **CLI ëª…ë ¹ì–´ ì¶”ê°€**
- `crud-visualization` ëª…ë ¹ì–´ ì¶”ê°€
- ë‹¤ìŒ ì˜µì…˜ë“¤ ì§€ì›:
  - `--project-name`: ë¶„ì„í•  í”„ë¡œì íŠ¸ ì´ë¦„ (í•„ìˆ˜)
  - `--output-file`: ë‹¤ì´ì–´ê·¸ë¨ì„ ì €ì¥í•  íŒŒì¼ (ì„ íƒ)
  - `--output-image`: ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë³€í™˜ (PNG/SVG/PDF)
  - `--image-format`: ì´ë¯¸ì§€ í˜•ì‹ (ê¸°ë³¸ê°’: png)
  - `--image-width`, `--image-height`: ì´ë¯¸ì§€ í¬ê¸°

### 3. **ì‹œê°í™” ê²°ê³¼**
- **í´ë˜ìŠ¤ ë…¸ë“œ**: ğŸ¢ ì•„ì´ì½˜ê³¼ í•¨ê»˜ í´ë˜ìŠ¤ëª… í‘œì‹œ
- **í…Œì´ë¸” ë…¸ë“œ**: ğŸ“Š ì•„ì´ì½˜ê³¼ í•¨ê»˜ í…Œì´ë¸”ëª… í‘œì‹œ
- **ì—°ê²°ì„ **: í´ë˜ìŠ¤ì—ì„œ í…Œì´ë¸”ë¡œì˜ CRUD ì—°ì‚° í‘œì‹œ
- **Mermaid í˜¸í™˜ì„±**: mermaid-clië¥¼ í†µí•œ ì´ë¯¸ì§€ ë³€í™˜ ì§€ì›

### 4. **ì‚¬ìš© ì˜ˆì‹œ**
```bash
# ê¸°ë³¸ ì‹œê°í™” (Markdown íŒŒì¼ë¡œ ì €ì¥)
python -m src.cli.main crud-visualization --project-name "car-center-devlab"

# ì´ë¯¸ì§€ë¡œ ë³€í™˜
python -m src.cli.main crud-visualization --project-name "car-center-devlab" --output-image "diagram.png"

# íŠ¹ì • íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
python -m src.cli.main crud-visualization --project-name "car-center-devlab" --output-file "my_diagram.md"
```

### 5. **ìƒì„±ëœ íŒŒì¼ë“¤**
- `crud_visualization_car-center-devlab.md`: Mermaid ë‹¤ì´ì–´ê·¸ë¨ì´ í¬í•¨ëœ Markdown íŒŒì¼
- `crud_visualization-1.png`: PNG ì´ë¯¸ì§€ íŒŒì¼ (17KB)

ì´ì œ ê°œë°œìë“¤ì´ ì–´í”Œë¦¬ì¼€ì´ì…˜ì˜ í´ë˜ìŠ¤ì™€ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê°„ì˜ í˜¸ì¶œ ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```shellscript
# ê¸°ë³¸ ì‹œê°í™” (Markdown íŒŒì¼ë¡œ ì €ì¥)
python -m src.cli.main crud-visualization --project-name "car-center-devlab"

# ì´ë¯¸ì§€ë¡œ ë³€í™˜
python -m src.cli.main crud-visualization --project-name "car-center-devlab" --output-image "diagram.png"

# íŠ¹ì • íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
python -m src.cli.main crud-visualization --project-name "car-center-devlab" --output-file "my_diagram.md"
```

---

**User**

CRUDëŠ” í‘œ í˜•íƒœë¡œ ìƒì„±í•´ì¤„ê²ƒ
ê°€ë¡œì¶•ì€ table, ì„¸ë¡œì¶•ì€ class

---

**Cursor**

CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤. ê°€ë¡œì¶•ì€ í…Œì´ë¸”, ì„¸ë¡œì¶•ì€ í´ë˜ìŠ¤ë¡œ êµ¬ì„±ëœ í‘œë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € `DBCallAnalysisService`ì— í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                row = {'class_name': class_name}
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            class_tables[table_name] = operations
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        operations = class_tables[table_name]
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        row[table_name] = ', '.join(sorted_ops) if sorted_ops else '-'
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

```

ì´ì œ CLIì˜ `crud_analysis` ëª…ë ¹ì–´ë¥¼ ìˆ˜ì •í•˜ì—¬ í‘œ í˜•íƒœë¡œ ì¶œë ¥í•˜ë„ë¡ ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤.


CLIì˜ `crud_analysis` ëª…ë ¹ì–´ë¥¼ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


ì´ì œ `crud_analysis` ëª…ë ¹ì–´ë¥¼ í‘œ í˜•íƒœë¡œ ì¶œë ¥í•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class"), max(len(name) for name in class_names)) if class_names else 10
            table_width = 8  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class':<{class_name_width}}"
            for table_name in table_names:
                header += f" {table_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                line = f"{class_name:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ ìˆ˜ì •ëœ CRUD ë¶„ì„ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í…Œì´ë¸”ì´ ë„ˆë¬´ ë„“ì–´ì„œ ê°€ë…ì„±ì´ ë–¨ì–´ì§€ë„¤ìš”. ì»¬ëŸ¼ ë„ˆë¹„ë¥¼ ì¡°ì •í•˜ê³  ë” ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class"), max(len(name) for name in class_names)) if class_names else 10
            table_width = 12  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„ (ë” ë„“ê²Œ)
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class':<{class_name_width}}"
            for table_name in table_names:
                header += f" {table_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                line = f"{class_name:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ë˜í•œ í…Œì´ë¸” ì´ë¦„ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ì˜ë¦¬ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í…Œì´ë¸” ì´ë¦„ì„ ì¤„ì—¬ì„œ í‘œì‹œí•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class"), max(len(name) for name in class_names)) if class_names else 10
            table_width = 12  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„ (ë” ë„“ê²Œ)
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class':<{class_name_width}}"
            for table_name in table_names:
                # í…Œì´ë¸” ì´ë¦„ì„ 10ìë¡œ ì œí•œ
                short_name = table_name[:10] if len(table_name) > 10 else table_name
                header += f" {short_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                line = f"{class_name:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ ìˆ˜ì •ëœ í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! ì´ì œ CRUD ë§¤íŠ¸ë¦­ìŠ¤ê°€ í‘œ í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ ì¶œë ¥ë©ë‹ˆë‹¤. 


## ì™„ë£Œ! CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ í˜•íƒœ êµ¬í˜„

ì„±ê³µì ìœ¼ë¡œ CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

### ğŸ¯ **êµ¬í˜„ëœ ê¸°ëŠ¥**

1. **í‘œ í˜•íƒœ CRUD ë§¤íŠ¸ë¦­ìŠ¤**
   - **ê°€ë¡œì¶•**: í…Œì´ë¸”ëª… (15ê°œ í…Œì´ë¸”)
   - **ì„¸ë¡œì¶•**: í´ë˜ìŠ¤ëª… (15ê°œ í´ë˜ìŠ¤)
   - **ì…€ ë‚´ìš©**: í•´ë‹¹ í´ë˜ìŠ¤ê°€ í•´ë‹¹ í…Œì´ë¸”ì— ìˆ˜í–‰í•˜ëŠ” CRUD ì—°ì‚° (C, R, U, D)

2. **ê°€ë…ì„± ê°œì„ **
   - í…Œì´ë¸”ëª…ì„ 10ìë¡œ ì œí•œí•˜ì—¬ í‘œ ë„ˆë¹„ ìµœì í™”
   - ê° ì»¬ëŸ¼ ë„ˆë¹„ë¥¼ 12ìë¡œ ì„¤ì •í•˜ì—¬ CRUD ì—°ì‚°ì´ ì˜ ë³´ì´ë„ë¡ ì¡°ì •
   - ì •ë ¬ëœ CRUD ì—°ì‚° í‘œì‹œ (C, D, R, U ìˆœì„œ)

3. **í‘œ êµ¬ì¡°**
   ```
   Class                                 notificati   notificati   notificati   payments     ...
   ------------------------------------- ------------ ------------ ------------ ------------ ...
   NotificationRepository                -            -            C, D, R, U   -            ...
   NotificationSettingsRepository        C, D, R, U   -            -            -            ...
   ```

### ğŸ“Š **í‘œ í•´ì„ ë°©ë²•**

- **C**: Create (INSERT)
- **R**: Read (SELECT)  
- **U**: Update (UPDATE)
- **D**: Delete (DELETE)
- **-**: í•´ë‹¹ í´ë˜ìŠ¤ê°€ í•´ë‹¹ í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

### ğŸ” **ì£¼ìš” íŠ¹ì§•**

1. **í•œëˆˆì— íŒŒì•… ê°€ëŠ¥**: ì–´ë–¤ í´ë˜ìŠ¤ê°€ ì–´ë–¤ í…Œì´ë¸”ì— ì–´ë–¤ ì—°ì‚°ì„ í•˜ëŠ”ì§€ í•œ í‘œì—ì„œ í™•ì¸
2. **ê´€ê³„ ë¶„ì„ ìš©ì´**: í´ë˜ìŠ¤ë³„ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© íŒ¨í„´ì„ ì‰½ê²Œ ë¶„ì„
3. **ì˜ì¡´ì„± íŒŒì•…**: í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ë“¤ì„ ë¹ ë¥´ê²Œ ì‹ë³„

ì´ì œ ê°œë°œìë“¤ì´ ì–´í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© íŒ¨í„´ì„ í‘œ í˜•íƒœë¡œ ì§ê´€ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```plaintext
   Class                                 notificati   notificati   notificati   payments     ...
   ------------------------------------- ------------ ------------ ------------ ------------ ...
   NotificationRepository                -            -            C, D, R, U   -            ...
   NotificationSettingsRepository        C, D, R, U   -            -            -            ...
```

---

**User**

CRUD Matrixë¥¼ MS-ExcelíŒŒì¼ë¡œ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •í•  ê²ƒ

---

**Cursor**

CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ MS-Excel íŒŒì¼ë¡œ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤. pandasì™€ openpyxlì„ ì‚¬ìš©í•´ì„œ Excel íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € í•„ìš”í•œ ì˜ì¡´ì„±ì„ í™•ì¸í•˜ê³  ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


pandasì™€ openpyxlì„ requirements.txtì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```pip-requirements
pytest
neo4j
javalang
click
pydantic
python-dotenv
PyYAML
pandas
openpyxl

```

ì´ì œ Excel íŒŒì¼ ìƒì„±ì„ ìœ„í•œ ê¸°ëŠ¥ì„ `DBCallAnalysisService`ì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                row = {'class_name': class_name}
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            class_tables[table_name] = operations
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        operations = class_tables[table_name]
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        row[table_name] = ', '.join(sorted_ops) if sorted_ops else '-'
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„±
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                row_data = {'Class': class_name}
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # DataFrameì„ ì›Œí¬ì‹œíŠ¸ì— ì¶”ê°€
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 2):  # Class ì»¬ëŸ¼ + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(2, len(class_names) + 2):
                for col in range(1, len(table_names) + 2):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col == 1:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ CLIì— Excel íŒŒì¼ ìƒì„± ì˜µì…˜ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--output-excel', help='Output Excel file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, output_excel, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class"), max(len(name) for name in class_names)) if class_names else 10
            table_width = 12  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„ (ë” ë„“ê²Œ)
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class':<{class_name_width}}"
            for table_name in table_names:
                # í…Œì´ë¸” ì´ë¦„ì„ 10ìë¡œ ì œí•œ
                short_name = table_name[:10] if len(table_name) > 10 else table_name
                header += f" {short_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                line = f"{class_name:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ Excel íŒŒì¼ ìƒì„± ë¡œì§ì„ CLIì— ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"CRUD matrix saved to: {output_file}")
        
        # Excel íŒŒì¼ë¡œ ì €ì¥
        if output_excel:
            success = analysis_service.generate_crud_excel(project_name, output_excel)
            if success:
                click.echo(f"CRUD matrix Excel file saved to: {output_excel}")
            else:
                click.echo("Failed to generate Excel file. Check logs for details.")
```

íŒŒì¼ì˜ í•´ë‹¹ ë¶€ë¶„ì„ ë‹¤ì‹œ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ ì •í™•í•œ ìœ„ì¹˜ì— Excel íŒŒì¼ ìƒì„± ë¡œì§ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--output-excel', help='Output Excel file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, output_excel, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class"), max(len(name) for name in class_names)) if class_names else 10
            table_width = 12  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„ (ë” ë„“ê²Œ)
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class':<{class_name_width}}"
            for table_name in table_names:
                # í…Œì´ë¸” ì´ë¦„ì„ 10ìë¡œ ì œí•œ
                short_name = table_name[:10] if len(table_name) > 10 else table_name
                header += f" {short_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                line = f"{class_name:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
        # Excel íŒŒì¼ë¡œ ì €ì¥
        if output_excel:
            success = analysis_service.generate_crud_excel(project_name, output_excel)
            if success:
                click.echo(f"CRUD matrix Excel file saved to: {output_excel}")
            else:
                click.echo("Failed to generate Excel file. Check logs for details.")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  Excel íŒŒì¼ ìƒì„± ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì´ì œ Excel íŒŒì¼ ìƒì„± ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! Excel íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„±ëœ íŒŒì¼ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


Excel íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ JSONê³¼ Excel íŒŒì¼ì„ í•¨ê»˜ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ë„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! **CRUD ë§¤íŠ¸ë¦­ìŠ¤ Excel íŒŒì¼ ìƒì„± ê¸°ëŠ¥**ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ **êµ¬í˜„ëœ ê¸°ëŠ¥ ìš”ì•½**

### 1. **Excel íŒŒì¼ ìƒì„± ê¸°ëŠ¥**
- **íŒŒì¼ í˜•ì‹**: `.xlsx` (Microsoft Excel 2007+ í˜¸í™˜)
- **ì›Œí¬ì‹œíŠ¸**: 2ê°œ ì‹œíŠ¸
  - `CRUD Matrix`: í´ë˜ìŠ¤-í…Œì´ë¸” ë§¤íŠ¸ë¦­ìŠ¤
  - `Summary`: í”„ë¡œì íŠ¸ ìš”ì•½ ì •ë³´

### 2. **Excel íŒŒì¼ íŠ¹ì§•**
- **ìŠ¤íƒ€ì¼ë§**: 
  - í—¤ë”: íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ ê¸€ì”¨, êµµì€ ê¸€ì”¨
  - í´ë˜ìŠ¤ ì»¬ëŸ¼: ì—°í•œ íŒŒë€ìƒ‰ ë°°ê²½, êµµì€ ê¸€ì”¨
  - ëª¨ë“  ì…€: í…Œë‘ë¦¬, ê°€ìš´ë° ì •ë ¬
- **ìë™ ë„ˆë¹„ ì¡°ì •**: ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ìµœì í™”
- **ìš”ì•½ ì •ë³´**: ë³„ë„ ì‹œíŠ¸ì— í†µê³„ ì •ë³´ í¬í•¨

### 3. **CLI ì˜µì…˜ ì¶”ê°€**
```bash
# Excel íŒŒì¼ë§Œ ìƒì„±
python -m src.cli.main crud-analysis --project-name "car-center-devlab" --output-excel "matrix.xlsx"

# JSONê³¼ Excel íŒŒì¼ ë™ì‹œ ìƒì„±
python -m src.cli.main crud-analysis --project-name "car-center-devlab" --output-file "matrix.json" --output-excel "matrix.xlsx"
```

### 4. **Excel íŒŒì¼ êµ¬ì¡°**

#### **CRUD Matrix ì‹œíŠ¸**
| Class | notification_settings | notification_templates | notifications | ... |
|-------|----------------------|----------------------|---------------|-----|
| NotificationRepository | - | - | C, D, R, U | ... |
| NotificationSettingsRepository | C, D, R, U | - | - | ... |

#### **Summary ì‹œíŠ¸**
- í”„ë¡œì íŠ¸ ì´ë¦„
- ì´ í´ë˜ìŠ¤ ìˆ˜, í…Œì´ë¸” ìˆ˜
- CRUD ì—°ì‚°ë³„ í†µê³„
- ê°€ì¥ í™œë°œí•œ í´ë˜ìŠ¤, ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ í…Œì´ë¸”

### 5. **ìƒì„±ëœ íŒŒì¼ë“¤**
- `crud_matrix_car-center-devlab.xlsx` (7KB)
- `crud_matrix.xlsx` (7KB)
- `crud_matrix.json` (JSON í˜•ì‹)

### 6. **ì˜ì¡´ì„± ì¶”ê°€**
- `pandas`: ë°ì´í„° ì²˜ë¦¬
- `openpyxl`: Excel íŒŒì¼ ìƒì„± ë° ìŠ¤íƒ€ì¼ë§

ì´ì œ ê°œë°œìë“¤ì´ CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ë°›ì•„ì„œ ì¶”ê°€ ë¶„ì„ì´ë‚˜ ë³´ê³ ì„œ ì‘ì„±ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```shellscript
# Excel íŒŒì¼ë§Œ ìƒì„±
python -m src.cli.main crud-analysis --project-name "car-center-devlab" --output-excel "matrix.xlsx"

# JSONê³¼ Excel íŒŒì¼ ë™ì‹œ ìƒì„±
python -m src.cli.main crud-analysis --project-name "car-center-devlab" --output-file "matrix.json" --output-excel "matrix.xlsx"
```

---

**User**

CRUD Matrix ê²°ê³¼ íŒŒì¼ì— classì˜ package nameì™€ tableì˜ schema nameì„ ì¶”ê°€í•  ê²ƒ

---

**Cursor**

CRUD Matrix ê²°ê³¼ íŒŒì¼ì— í´ë˜ìŠ¤ì˜ package nameê³¼ í…Œì´ë¸”ì˜ schema nameì„ ì¶”ê°€í•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € `generate_crud_table_matrix` ë©”ì„œë“œë¥¼ ìˆ˜ì •í•˜ì—¬ package nameê³¼ schema name ì •ë³´ë¥¼ í¬í•¨í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        schema_name = table_info['schema_name']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        # ìŠ¤í‚¤ë§ˆ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
                        row[table_name] = f"{operations_str} ({schema_name})"
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„±
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                row_data = {'Class': class_name}
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # DataFrameì„ ì›Œí¬ì‹œíŠ¸ì— ì¶”ê°€
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 2):  # Class ì»¬ëŸ¼ + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(2, len(class_names) + 2):
                for col in range(1, len(table_names) + 2):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col == 1:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ CLI í‘œì‹œ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ package nameê³¼ schema nameì„ í¬í•¨í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


```python
import click
import sys
import os
from dotenv import load_dotenv

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from src.services.java_parser import parse_java_project
from src.services.graph_db import GraphDB
from src.services.sequence_diagram_generator import SequenceDiagramGenerator
from src.services.db_parser import DBParser
from src.services.db_call_analysis import DBCallAnalysisService
from neo4j import GraphDatabase
import subprocess
import tempfile

load_dotenv()

def convert_to_image(diagram_content, output_file, image_format, width, height):
    """Convert Mermaid diagram to image using mermaid-cli"""
    # Try different possible locations for mmdc
    mmdc_commands = ['mmdc', 'mmdc.cmd', r'C:\Users\cjony\AppData\Roaming\npm\mmdc', r'C:\Users\cjony\AppData\Roaming\npm\mmdc.cmd']
    
    mmdc_cmd = None
    for cmd in mmdc_commands:
        try:
            subprocess.run([cmd, '--version'], capture_output=True, check=True, timeout=5)
            mmdc_cmd = cmd
            break
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            continue
    
    if not mmdc_cmd:
        click.echo("Error: mermaid-cli is not installed or not found in PATH.")
        click.echo("Please install it with: npm install -g @mermaid-js/mermaid-cli")
        click.echo("Or check if it's installed at: C:\\Users\\cjony\\AppData\\Roaming\\npm\\")
        return
    
    try:
        # Create temporary file for mermaid content
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8', newline='') as temp_file:
            temp_file.write(diagram_content)
            temp_file_path = temp_file.name
        
        # Determine format from output file extension
        file_extension = output_file.split('.')[-1].lower()
        actual_format = file_extension if file_extension in ['png', 'svg', 'pdf'] else image_format
        
        # Convert to image using mermaid-cli
        cmd = [
            mmdc_cmd,
            '-i', temp_file_path,
            '-o', output_file,
            '-e', actual_format,
            '-w', str(width),
            '-H', str(height)
        ]
        
        # Add PDF-specific options
        if image_format.lower() == 'pdf':
            # Set background color for PDF
            cmd.extend(['-b', 'white'])
            # Add PDF fit option
            cmd.append('-f')
        
        click.echo(f"Running command: {' '.join(cmd)}")
        
        # Set environment variables for UTF-8 encoding
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        env['LANG'] = 'en_US.UTF-8'
        env['LC_ALL'] = 'en_US.UTF-8'
        
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8', errors='ignore', env=env)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        # Check if the expected output file was created
        if os.path.exists(output_file):
            actual_format = output_file.split('.')[-1].upper()
            click.echo(f"Image saved to: {output_file}")
            click.echo(f"Format: {actual_format}, Size: {width}x{height}")
        else:
            # Check for files with similar names (mermaid-cli sometimes adds numbers)
            import glob
            pattern = output_file.replace('.pdf', '-*.pdf').replace('.png', '-*.png').replace('.svg', '-*.svg')
            matching_files = glob.glob(pattern)
            if matching_files:
                actual_file = matching_files[0]
                actual_format = actual_file.split('.')[-1].upper()
                click.echo(f"Image saved to: {actual_file}")
                click.echo(f"Format: {actual_format}, Size: {width}x{height}")
                click.echo(f"Note: mermaid-cli created {actual_file} instead of {output_file}")
            else:
                click.echo(f"Warning: Expected file {output_file} not found")
        
        click.echo(f"Command output: {result.stdout}")
        
    except subprocess.CalledProcessError as e:
        click.echo(f"Error converting to image: {e}")
        click.echo(f"Error output: {e.stderr}")
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
    except Exception as e:
        click.echo(f"Unexpected error: {e}")
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)

@click.group()
def cli():
    pass

@cli.command()
@click.option('--java-source-folder', default=os.getenv("JAVA_SOURCE_FOLDER"), help='Path to the Java source project folder.')
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--clean', is_flag=True, help='Wipe the database before analysis.')
@click.option('--class-name', help='Analyze only a specific class (delete existing data for this class first)')
@click.option('--update', is_flag=True, help='Update all classes individually without clearing database')
@click.option('--db_object', is_flag=True, help='Analyze database objects from DDL scripts')
@click.option('--java_object', is_flag=True, help='Analyze Java objects from source code')
@click.option('--dry-run', is_flag=True, help='Parse Java files without connecting to database.')
def analyze(java_source_folder, neo4j_uri, neo4j_user, neo4j_password, clean, class_name, update, db_object, java_object, dry_run):
    """Analyzes a Java project and populates a Neo4j database."""
    if not java_source_folder:
        click.echo("Error: JAVA_SOURCE_FOLDER environment variable or --java-source-folder option is required.", err=True)
        exit(1)

    # Extract project name from directory path
    from pathlib import Path
    project_name = Path(java_source_folder).resolve().name

    # Handle Java object analysis
    if java_object:
        click.echo("Analyzing Java objects from source code...")
        
        if not java_source_folder:
            click.echo("Error: JAVA_SOURCE_FOLDER environment variable is required for --java_object option.", err=True)
            click.echo("Please set JAVA_SOURCE_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(java_source_folder):
            click.echo(f"Error: Java source folder {java_source_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse Java project
            click.echo(f"Parsing Java project at: {java_source_folder}")
            packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
            
            click.echo(f"Project name: {project_name}")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
                click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
                click.echo(f"Found {len(endpoints)} REST API endpoints.")
                click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
                click.echo(f"Found {len(jpa_entities)} JPA entities.")
                click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
                click.echo(f"Found {len(jpa_queries)} JPA queries.")
                click.echo(f"Found {len(config_files)} configuration files.")
                click.echo(f"Found {len(test_classes)} test classes.")
                click.echo(f"Found {len(sql_statements)} SQL statements.")
                click.echo("Java object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning Java objects...")
                with db._driver.session() as session:
                    # Delete only Java-related nodes
                    session.run("MATCH (n:Package) DETACH DELETE n")
                    session.run("MATCH (n:Class) DETACH DELETE n")
                    session.run("MATCH (n:Method) DETACH DELETE n")
                    session.run("MATCH (n:Field) DETACH DELETE n")
                    session.run("MATCH (n:Bean) DETACH DELETE n")
                    session.run("MATCH (n:Endpoint) DETACH DELETE n")
                    session.run("MATCH (n:MyBatisMapper) DETACH DELETE n")
                    session.run("MATCH (n:JpaEntity) DETACH DELETE n")
                    session.run("MATCH (n:ConfigFile) DETACH DELETE n")
                    session.run("MATCH (n:TestClass) DETACH DELETE n")
                    session.run("MATCH (n:SqlStatement) DETACH DELETE n")
            
            # Add packages
            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
            
            # Add classes
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Java object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing Java objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # Handle DB object analysis
    if db_object:
        click.echo("Analyzing database objects from DDL scripts...")
        
        # Get DB script folder from environment variable
        db_script_folder = os.getenv("DB_SCRIPT_FOLDER")
        if not db_script_folder:
            click.echo("Error: DB_SCRIPT_FOLDER environment variable is required for --db_object option.", err=True)
            click.echo("Please set DB_SCRIPT_FOLDER in your .env file or environment variables.")
            exit(1)
        
        if not os.path.exists(db_script_folder):
            click.echo(f"Error: DB script folder {db_script_folder} does not exist.", err=True)
            exit(1)
        
        try:
            # Parse DDL files
            db_parser = DBParser()
            all_db_objects = db_parser.parse_ddl_directory(db_script_folder, project_name)
            
            if not all_db_objects:
                click.echo("No DDL files found or parsed successfully.")
                return
            
            click.echo(f"Found {len(all_db_objects)} DDL files to process.")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                for i, db_objects in enumerate(all_db_objects):
                    click.echo(f"DDL file {i+1}:")
                    click.echo(f"  Database: {db_objects['database'].name}")
                    click.echo(f"  Tables: {len(db_objects['tables'])}")
                    click.echo(f"  Columns: {len(db_objects['columns'])}")
                    click.echo(f"  Indexes: {len(db_objects['indexes'])}")
                    click.echo(f"  Constraints: {len(db_objects['constraints'])}")
                click.echo("DB object analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            if clean:
                click.echo("Cleaning database objects...")
                with db._driver.session() as session:
                    # Delete only database-related nodes
                    session.run("MATCH (n:Database) DETACH DELETE n")
                    session.run("MATCH (n:Table) DETACH DELETE n")
                    session.run("MATCH (n:Column) DETACH DELETE n")
                    session.run("MATCH (n:Index) DETACH DELETE n")
                    session.run("MATCH (n:Constraint) DETACH DELETE n")
            
            # Process each DDL file's objects
            for i, db_objects in enumerate(all_db_objects):
                click.echo(f"Processing DDL file {i+1}...")
                
                # Add database
                click.echo(f"Adding database: {db_objects['database'].name}")
                db.add_database(db_objects['database'], project_name)
                
                # Add tables
                for table_obj in db_objects['tables']:
                    click.echo(f"Adding table: {table_obj.name}")
                    db.add_table(table_obj, db_objects['database'].name, project_name)
                
                # Add columns
                for column_obj in db_objects['columns']:
                    table_name = getattr(column_obj, 'table_name', 'unknown')
                    click.echo(f"Adding column: {column_obj.name} to table {table_name}")
                    db.add_column(column_obj, table_name, project_name)
                
                # Add indexes
                for index_obj, table_name in db_objects['indexes']:
                    click.echo(f"Adding index: {index_obj.name} to table {table_name}")
                    db.add_index(index_obj, table_name, project_name)
                
                # Add constraints
                for constraint_obj, table_name in db_objects['constraints']:
                    click.echo(f"Adding constraint: {constraint_obj.name} to table {table_name}")
                    db.add_constraint(constraint_obj, table_name, project_name)
            
            db.close()
            click.echo("DB object analysis complete.")
            return
            
        except Exception as e:
            click.echo(f"Error analyzing DB objects: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

    # If analyzing a specific class
    if class_name:
        click.echo(f"Analyzing specific class: {class_name}")
        
        # Find the Java file for this class
        java_file_path = None
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java") and file.replace(".java", "") == class_name:
                    java_file_path = os.path.join(root, file)
                    break
            if java_file_path:
                break
        
        if not java_file_path:
            click.echo(f"Error: Could not find Java file for class '{class_name}'", err=True)
            exit(1)
        
        click.echo(f"Found Java file: {java_file_path}")
        
        try:
            # Parse the single Java file
            from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
            
            package_node, class_node, package_name = parse_single_java_file(java_file_path, project_name)
            
            click.echo(f"Parsed class: {class_node.name}")
            click.echo(f"Package: {package_name}")
            click.echo(f"Methods: {len(class_node.methods)}")
            click.echo(f"Properties: {len(class_node.properties)}")
            click.echo(f"Method calls: {len(class_node.calls)}")
            
            if dry_run:
                click.echo("Dry run mode - not connecting to database.")
                click.echo("Analysis complete (dry run).")
                return
            
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            # Delete existing data for this class
            click.echo(f"Deleting existing data for class '{class_name}'...")
            db.delete_class_and_related_data(class_name, project_name)
            
            # Add package
            click.echo("Adding package to database...")
            db.add_package(package_node, project_name)
            
            # Add class
            click.echo("Adding class to database...")
            db.add_class(class_node, package_name, project_name)
            
            # Extract and add related Spring Boot analysis results for this class only
            classes_list = [class_node]
            beans = extract_beans_from_classes(classes_list)
            dependencies = analyze_bean_dependencies(classes_list, beans)
            endpoints = extract_endpoints_from_classes(classes_list)
            mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
            jpa_entities = extract_jpa_entities_from_classes(classes_list)
            test_classes = extract_test_classes_from_classes(classes_list)
            
            # Extract SQL statements from MyBatis mappers
            sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
            
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
            
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
            
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
            
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
            
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
            
            db.close()
            click.echo("Class analysis complete.")
            
        except Exception as e:
            click.echo(f"Error analyzing class: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # If updating all classes individually
    if update:
        click.echo("Updating all classes individually...")
        
        # Find all Java files
        java_files = []
        for root, _, files in os.walk(java_source_folder):
            for file in files:
                if file.endswith(".java"):
                    java_files.append(os.path.join(root, file))
        
        if not java_files:
            click.echo("No Java files found in the specified directory.", err=True)
            exit(1)
        
        click.echo(f"Found {len(java_files)} Java files to process.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            for java_file in java_files:
                try:
                    from src.services.java_parser import parse_single_java_file
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    click.echo(f"  {class_node.name} ({package_name}) - Methods: {len(class_node.methods)}, Properties: {len(class_node.properties)}")
                except Exception as e:
                    click.echo(f"  Error parsing {java_file}: {e}")
            click.echo("Update analysis complete (dry run).")
            return
        
        try:
            # Connect to database
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
            
            processed_count = 0
            error_count = 0
            
            for java_file in java_files:
                try:
                    click.echo(f"Processing: {java_file}")
                    
                    # Parse the single Java file
                    from src.services.java_parser import parse_single_java_file, extract_beans_from_classes, analyze_bean_dependencies, extract_endpoints_from_classes, extract_mybatis_mappers_from_classes, extract_jpa_entities_from_classes, extract_test_classes_from_classes, extract_sql_statements_from_mappers
                    
                    package_node, class_node, package_name = parse_single_java_file(java_file, project_name)
                    
                    click.echo(f"  Parsed class: {class_node.name} (Package: {package_name})")
                    
                    # Delete existing data for this class
                    click.echo(f"  Deleting existing data for class '{class_node.name}'...")
                    db.delete_class_and_related_data(class_node.name, project_name)
                    
                    # Add package
                    db.add_package(package_node, project_name)
                    
                    # Add class
                    db.add_class(class_node, package_name, project_name)
                    
                    # Extract and add related Spring Boot analysis results for this class only
                    classes_list = [class_node]
                    beans = extract_beans_from_classes(classes_list)
                    dependencies = analyze_bean_dependencies(classes_list, beans)
                    endpoints = extract_endpoints_from_classes(classes_list)
                    mybatis_mappers = extract_mybatis_mappers_from_classes(classes_list)
                    jpa_entities = extract_jpa_entities_from_classes(classes_list)
                    test_classes = extract_test_classes_from_classes(classes_list)
                    
                    # Extract SQL statements from MyBatis mappers
                    sql_statements = extract_sql_statements_from_mappers(mybatis_mappers, project_name)
                    
                    # Add Spring Boot analysis results
                    if beans:
                        for bean in beans:
                            db.add_bean(bean, project_name)
                    
                    if dependencies:
                        for dependency in dependencies:
                            db.add_bean_dependency(dependency, project_name)
                    
                    if endpoints:
                        for endpoint in endpoints:
                            db.add_endpoint(endpoint, project_name)
                    
                    if mybatis_mappers:
                        for mapper in mybatis_mappers:
                            db.add_mybatis_mapper(mapper, project_name)
                    
                    if jpa_entities:
                        for entity in jpa_entities:
                            db.add_jpa_entity(entity, project_name)
                    
                    if test_classes:
                        for test_class in test_classes:
                            db.add_test_class(test_class, project_name)
                    
                    if sql_statements:
                        for sql_statement in sql_statements:
                            db.add_sql_statement(sql_statement, project_name)
                            # Create relationship between mapper and SQL statement
                            with db._driver.session() as session:
                                session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
                    
                    processed_count += 1
                    click.echo(f"  [OK] Successfully processed {class_node.name}")
                    
                except Exception as e:
                    error_count += 1
                    click.echo(f"  [ERROR] Error processing {java_file}: {e}")
                    continue
            
            db.close()
            click.echo(f"Update complete. Processed: {processed_count}, Errors: {error_count}")
            
        except Exception as e:
            click.echo(f"Error during update: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)
        
        return

    # Original full project analysis (when no specific object type is specified)
    if not java_object and not db_object:
        click.echo(f"Parsing Java project at: {java_source_folder}")
        packages_to_add, classes_to_add, class_to_package_map, beans, dependencies, endpoints, mybatis_mappers, jpa_entities, jpa_repositories, jpa_queries, config_files, test_classes, sql_statements, project_name = parse_java_project(java_source_folder)
    
        click.echo(f"Project name: {project_name}")
        
        click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
        
        if dry_run:
            click.echo("Dry run mode - not connecting to database.")
            click.echo(f"Found {len(packages_to_add)} packages and {len(classes_to_add)} classes.")
            click.echo(f"Found {len(beans)} Spring Beans and {len(dependencies)} dependencies.")
            click.echo(f"Found {len(endpoints)} REST API endpoints.")
            click.echo(f"Found {len(mybatis_mappers)} MyBatis mappers.")
            click.echo(f"Found {len(jpa_entities)} JPA entities.")
            click.echo(f"Found {len(jpa_repositories)} JPA repositories.")
            click.echo(f"Found {len(jpa_queries)} JPA queries.")
            click.echo(f"Found {len(config_files)} configuration files.")
            click.echo(f"Found {len(test_classes)} test classes.")
            click.echo(f"Found {len(sql_statements)} SQL statements.")
            
            for package_node in packages_to_add:
                click.echo(f"Package: {package_node.name}")
            for class_node in classes_to_add:
                click.echo(f"Class: {class_node.name}")
                click.echo(f"  Methods: {len(class_node.methods)}")
                click.echo(f"  Properties: {len(class_node.properties)}")
                click.echo(f"  Method calls: {len(class_node.calls)}")
            click.echo("Analysis complete (dry run).")
            return

        try:
            click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
            db = GraphDB(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)

            if clean:
                click.echo("Cleaning database...")
                with db._driver.session() as session:
                    session.run("MATCH (n) DETACH DELETE n")

            click.echo("Adding packages to database...")
            for package_node in packages_to_add:
                db.add_package(package_node, project_name)
        
            click.echo("Adding classes to database...")
            for class_node in classes_to_add:
                # Find the package for this class using the mapping
                class_key = f"{class_to_package_map.get(class_node.name, '')}.{class_node.name}"
                package_name = class_to_package_map.get(class_key, None)
                
                if not package_name:
                    # Fallback: try to find package by class name
                    for key, pkg_name in class_to_package_map.items():
                        if key.endswith(f".{class_node.name}"):
                            package_name = pkg_name
                            break
                
                db.add_class(class_node, package_name, project_name)
        
            # Add Spring Boot analysis results
            if beans:
                click.echo(f"Adding {len(beans)} Spring Beans to database...")
                for bean in beans:
                    db.add_bean(bean, project_name)
        
            if dependencies:
                click.echo(f"Adding {len(dependencies)} Bean dependencies to database...")
                for dependency in dependencies:
                    db.add_bean_dependency(dependency, project_name)
        
            if endpoints:
                click.echo(f"Adding {len(endpoints)} REST API endpoints to database...")
                for endpoint in endpoints:
                    db.add_endpoint(endpoint, project_name)
        
            if mybatis_mappers:
                click.echo(f"Adding {len(mybatis_mappers)} MyBatis mappers to database...")
                for mapper in mybatis_mappers:
                    db.add_mybatis_mapper(mapper, project_name)
            
            if jpa_entities:
                click.echo(f"Adding {len(jpa_entities)} JPA entities to database...")
                for entity in jpa_entities:
                    db.add_jpa_entity(entity, project_name)
            
            if jpa_repositories:
                click.echo(f"Adding {len(jpa_repositories)} JPA repositories to database...")
                for repository in jpa_repositories:
                    db.add_jpa_repository(repository, project_name)
            
            if jpa_queries:
                click.echo(f"Adding {len(jpa_queries)} JPA queries to database...")
                for query in jpa_queries:
                    db.add_jpa_query(query, project_name)
            
            if config_files:
                click.echo(f"Adding {len(config_files)} configuration files to database...")
                for config_file in config_files:
                    db.add_config_file(config_file, project_name)
        
            if test_classes:
                click.echo(f"Adding {len(test_classes)} test classes to database...")
                for test_class in test_classes:
                    db.add_test_class(test_class, project_name)
        
            if sql_statements:
                click.echo(f"Adding {len(sql_statements)} SQL statements to database...")
                for sql_statement in sql_statements:
                    db.add_sql_statement(sql_statement, project_name)
                    # Create relationship between mapper and SQL statement
                    with db._driver.session() as session:
                        session.execute_write(db._create_mapper_sql_relationship_tx, sql_statement.mapper_name, sql_statement.id, project_name)
        
            db.close()
            click.echo("Analysis complete.")
        except Exception as e:
            click.echo(f"Error connecting to database: {e}")
            click.echo("Use --dry-run flag to parse without database connection.")
            exit(1)

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--neo4j-password', default=os.getenv("NEO4J_PASSWORD"), help='Neo4j password')
@click.option('--query', help='Custom Cypher query to execute')
@click.option('--basic', is_flag=True, help='Run basic class query')
@click.option('--detailed', is_flag=True, help='Run detailed class query with methods and properties')
@click.option('--inheritance', is_flag=True, help='Run inheritance relationship query')
@click.option('--package', is_flag=True, help='Run package-based class query')
def query(neo4j_uri, neo4j_user, neo4j_password, query, basic, detailed, inheritance, package):
    """Execute queries against the Neo4j database."""
    
    # ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ë“¤
    queries = {
        'basic': """
        MATCH (c:Class)
        RETURN 
            c.name AS name,
            c.logical_name AS logical_name,
            c.file_path AS file_path,
            c.type AS type,
            c.source AS source
        ORDER BY c.name
        """,
        'detailed': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        OPTIONAL MATCH (pkg:Package)-[:CONTAINS]->(c)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.file_path AS file_path,
            c.type AS class_type,
            pkg.name AS package_name,
            collect(DISTINCT m.name) AS methods,
            collect(DISTINCT p.name) AS properties
        ORDER BY c.name
        """,
        'inheritance': """
        MATCH (c:Class)
        OPTIONAL MATCH (c)-[:EXTENDS]->(super:Class)
        OPTIONAL MATCH (c)-[:IMPLEMENTS]->(impl:Class)
        RETURN 
            c.name AS class_name,
            c.logical_name AS class_logical_name,
            c.type AS class_type,
            collect(DISTINCT super.name) AS extends,
            collect(DISTINCT impl.name) AS implements
        ORDER BY c.name
        """,
        'package': """
        MATCH (pkg:Package)-[:CONTAINS]->(c:Class)
        OPTIONAL MATCH (c)-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (c)-[:HAS_FIELD]->(p:Field)
        RETURN 
            pkg.name AS package_name,
            pkg.logical_name AS package_logical_name,
            collect(DISTINCT c.name) AS classes,
            count(DISTINCT m) AS total_methods,
            count(DISTINCT p) AS total_properties
        ORDER BY pkg.name
        """
    }
    
    # ì‹¤í–‰í•  ì¿¼ë¦¬ ê²°ì •
    if query:
        cypher_query = query
        description = "Custom Query"
    elif basic:
        cypher_query = queries['basic']
        description = "Basic Class Query"
    elif detailed:
        cypher_query = queries['detailed']
        description = "Detailed Class Query"
    elif inheritance:
        cypher_query = queries['inheritance']
        description = "Inheritance Query"
    elif package:
        cypher_query = queries['package']
        description = "Package Query"
    else:
        click.echo("Error: Please specify a query type or provide a custom query.")
        click.echo("Available options: --basic, --detailed, --inheritance, --package, or --query")
        return
    
    try:
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        with driver.session() as session:
            click.echo(f"Executing: {description}")
            click.echo("=" * 50)
            
            result = session.run(cypher_query)
            records = list(result)
            
            if not records:
                click.echo("No results found.")
                return
            
            # ì²« ë²ˆì§¸ ë ˆì½”ë“œì˜ í‚¤ë“¤ì„ í—¤ë”ë¡œ ì‚¬ìš©
            headers = list(records[0].keys())
            
            # í—¤ë” ì¶œë ¥
            click.echo(" | ".join(f"{header:20}" for header in headers))
            click.echo("-" * (len(headers) * 23))
            
            # ë°ì´í„° ì¶œë ¥
            for record in records:
                row = []
                for header in headers:
                    value = record[header]
                    if value is None:
                        row.append("None")
                    elif isinstance(value, (list, dict)):
                        row.append(str(value)[:50] + "..." if len(str(value)) > 50 else str(value))
                    else:
                        row.append(str(value)[:20])
                click.echo(" | ".join(f"{cell:20}" for cell in row))
            
            click.echo(f"\nTotal: {len(records)} results found.")
            
    except Exception as e:
        click.echo(f"Error executing query: {e}")
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to analyze')
@click.option('--method-name', help='Specific method to analyze (optional)')
@click.option('--max-depth', default=3, help='Maximum depth of call chain to follow (default: 3)')
@click.option('--include-external', is_flag=True, help='Include calls to external libraries')
@click.option('--method-focused', is_flag=True, help='Generate method-focused diagram (shows only the specified method and its direct calls)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def sequence(neo4j_uri, neo4j_user, class_name, method_name, max_depth, include_external, method_focused, output_file, output_image, image_format, image_width, image_height):
    """Generate sequence diagram for a specific class and optionally a method."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        click.echo(f"Connecting to Neo4j at {neo4j_uri}...")
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        # Generate the sequence diagram
        click.echo(f"Generating sequence diagram for class: {class_name}")
        if method_name:
            click.echo(f"Focusing on method: {method_name}")
        if method_focused:
            click.echo("Method-focused mode: showing only direct calls from the specified method")
        
        diagram = generator.generate_sequence_diagram(
            class_name=class_name,
            method_name=method_name,
            max_depth=max_depth if not method_focused else 1,  # Method-focused uses depth 1
            include_external_calls=include_external,
            method_focused=method_focused
        )
        
        click.echo(f"Diagram generated (length: {len(diagram)})")
        
        # Check if diagram contains error message
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # Output the diagram
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {output_file}")
        else:
            # Default: save to {class_name}.md
            default_filename = f"{class_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Sequence diagram saved to: {default_filename}")
            
            click.echo("\n" + "="*50)
            click.echo("SEQUENCE DIAGRAM")
            click.echo("="*50)
            click.echo(diagram)
            click.echo("="*50)
        
        # Convert to image if requested
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
    except Exception as e:
        click.echo(f"Error generating sequence diagram: {e}")
        import traceback
        click.echo(f"Traceback: {traceback.format_exc()}")
        exit(1)
    finally:
        if 'driver' in locals():
            driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
def list_classes(neo4j_uri, neo4j_user):
    """List all available classes in the database."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        classes = generator.get_available_classes()
        
        if not classes:
            click.echo("No classes found in the database.")
            return
        
        click.echo("Available classes:")
        click.echo("=" * 80)
        click.echo(f"{'Class Name':<30} {'Package':<30} {'Type':<10}")
        click.echo("-" * 80)
        
        for cls in classes:
            click.echo(f"{cls['name']:<30} {cls['package_name']:<30} {cls['type']:<10}")
        
        click.echo(f"\nTotal: {len(classes)} classes found.")
        
    except Exception as e:
        click.echo(f"Error listing classes: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--class-name', required=True, help='Name of the class to list methods for')
def list_methods(neo4j_uri, neo4j_user, class_name):
    """List all methods for a specific class."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        generator = SequenceDiagramGenerator(driver)
        
        methods = generator.get_class_methods(class_name)
        
        if not methods:
            click.echo(f"No methods found for class '{class_name}'.")
            return
        
        click.echo(f"Methods for class '{class_name}':")
        click.echo("=" * 80)
        click.echo(f"{'Method Name':<30} {'Return Type':<20} {'Logical Name':<30}")
        click.echo("-" * 80)
        
        for method in methods:
            click.echo(f"{method['name']:<30} {method['return_type']:<20} {method['logical_name']:<30}")
        
        click.echo(f"\nTotal: {len(methods)} methods found.")
        
    except Exception as e:
        click.echo(f"Error listing methods: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def crud_matrix(neo4j_uri, neo4j_user, project_name):
    """Show CRUD matrix for classes and tables."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("CRUD Matrix - Class to Table Operations")
        click.echo("=" * 80)
        
        matrix = db.get_crud_matrix(project_name)
        
        if not matrix:
            click.echo("No CRUD operations found.")
            return
        
        click.echo(f"{'Class Name':<30} {'Package':<25} {'Tables':<20} {'Operations':<15}")
        click.echo("-" * 80)
        
        for row in matrix:
            class_name = row['class_name']
            package_name = row['package_name'] or 'N/A'
            tables = ', '.join(row['tables']) if row['tables'] else 'None'
            operations = ', '.join(row['operations']) if row['operations'] else 'None'
            
            click.echo(f"{class_name:<30} {package_name:<25} {tables:<20} {operations:<15}")
        
        click.echo(f"\nTotal: {len(matrix)} classes with CRUD operations.")
        
    except Exception as e:
        click.echo(f"Error getting CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def db_analysis(neo4j_uri, neo4j_user, project_name):
    """Show database call relationship analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Database Call Relationship Analysis")
        click.echo("=" * 80)
        
        # SQL ë¬¸ í†µê³„
        sql_stats = db.get_sql_statistics(project_name)
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        table_stats = db.get_table_usage_statistics(project_name)
        if table_stats:
            click.echo(f"\nTable Usage Statistics:")
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 65)
            for table in table_stats:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ ë¶„ì„
        complexity_stats = db.get_sql_complexity_statistics(project_name)
        if complexity_stats:
            click.echo(f"\nSQL Complexity Analysis:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # ë§¤í¼ë³„ SQL ë¶„í¬
        mapper_stats = db.get_mapper_sql_distribution(project_name)
        if mapper_stats:
            click.echo(f"\nMapper SQL Distribution:")
            click.echo(f"{'Mapper Name':<30} {'SQL Count':<15} {'SQL Types':<20}")
            click.echo("-" * 65)
            for mapper in mapper_stats:
                mapper_name = mapper['mapper_name']
                sql_count = mapper['sql_count']
                sql_types = ', '.join(mapper['sql_types'])
                click.echo(f"{mapper_name:<30} {sql_count:<15} {sql_types:<20}")
        
    except Exception as e:
        click.echo(f"Error getting database analysis: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', help='Project name to filter by (optional)')
def table_summary(neo4j_uri, neo4j_user, project_name):
    """Show CRUD summary for each table."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
        
        click.echo("Table CRUD Summary")
        click.echo("=" * 60)
        
        summary = db.get_table_crud_summary(project_name)
        
        if not summary:
            click.echo("No tables found.")
            return
        
        for row in summary:
            table_name = row['table_name']
            operations = row['operations']
            
            click.echo(f"\nTable: {table_name}")
            click.echo("-" * 40)
            
            for op in operations:
                operation = op['operation']
                count = op['count']
                click.echo(f"  {operation}: {count} statements")
        
        click.echo(f"\nTotal: {len(summary)} tables.")
        
    except Exception as e:
        click.echo(f"Error getting table summary: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for call chain analysis (optional)')
@click.option('--start-method', help='Starting method for call chain analysis (optional)')
@click.option('--output-file', help='Output file to save the analysis results (optional)')
def db_call_chain(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file):
    """Analyze database call chain relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Analysis")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Analyzing call chain from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Analyzing call chain from class {start_class}")
        else:
            click.echo(f"Analyzing call chain for project {project_name}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = analysis_service.analyze_call_chain(project_name, start_class, start_method)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        # ê²°ê³¼ ì¶œë ¥
        call_chain = result['call_chain']
        missing_nodes = result['missing_nodes']
        summary = result['analysis_summary']
        
        click.echo(f"\nAnalysis Summary:")
        click.echo(f"  Total calls: {summary['total_calls']}")
        click.echo(f"  Unique classes: {summary['unique_classes']}")
        click.echo(f"  Unique methods: {summary['unique_methods']}")
        click.echo(f"  Unique SQL statements: {summary['unique_sql_statements']}")
        click.echo(f"  Unique tables: {summary['unique_tables']}")
        click.echo(f"  Unique columns: {summary['unique_columns']}")
        click.echo(f"  Missing tables: {summary['missing_tables_count']}")
        click.echo(f"  Missing columns: {summary['missing_columns_count']}")
        
        if missing_nodes['missing_tables']:
            click.echo(f"\nMissing Tables (âŒ):")
            for table in missing_nodes['missing_tables']:
                click.echo(f"  - {table}")
        
        if missing_nodes['missing_columns']:
            click.echo(f"\nMissing Columns (âŒ):")
            for column in missing_nodes['missing_columns']:
                click.echo(f"  - {column}")
        
        # í˜¸ì¶œ ì²´ì¸ ìƒì„¸ ì •ë³´
        if call_chain:
            click.echo(f"\nCall Chain Details:")
            click.echo("-" * 80)
            click.echo(f"{'Source':<25} {'Target':<25} {'SQL Type':<10} {'Table':<20}")
            click.echo("-" * 80)
            
            for call in call_chain[:20]:  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
                source = f"{call['source_class']}.{call['source_method']}" if call['source_method'] else call['source_class']
                target = f"{call['target_class']}.{call['target_method']}" if call['target_method'] else call['target_class']
                sql_type = call['sql_type'] or 'N/A'
                table = call['table_name'] or 'N/A'
                
                click.echo(f"{source:<25} {target:<25} {sql_type:<10} {table:<20}")
            
            if len(call_chain) > 20:
                click.echo(f"... and {len(call_chain) - 20} more calls")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nAnalysis results saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing call chain: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the CRUD matrix (optional)')
@click.option('--output-excel', help='Output Excel file to save the CRUD matrix (optional)')
@click.option('--create-relationships', is_flag=True, help='Create Method-SqlStatement relationships before analysis')
def crud_analysis(neo4j_uri, neo4j_user, project_name, output_file, output_excel, create_relationships):
    """Generate CRUD matrix analysis."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        
        # Method-SqlStatement ê´€ê³„ ìƒì„± (ì˜µì…˜)
        if create_relationships:
            click.echo("Creating Method-SqlStatement relationships...")
            graph_db = GraphDB(neo4j_uri, neo4j_user, neo4j_password)
            relationships_created = graph_db.create_method_sql_relationships(project_name)
            click.echo(f"Created {relationships_created} Method-SqlStatement relationships.")
        
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Analysis (SQL í˜¸ì¶œ í´ë˜ìŠ¤ë§Œ)")
        click.echo("=" * 50)
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (í‘œ í˜•íƒœ)
        result = analysis_service.generate_crud_table_matrix(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        table_matrix = result['table_matrix']
        class_names = result['class_names']
        table_names = result['table_names']
        summary = result['summary']
        
        click.echo(f"\nCRUD Summary:")
        click.echo(f"  Total classes: {summary['total_classes']}")
        click.echo(f"  Total tables: {summary['total_tables']}")
        click.echo(f"  Create operations: {summary['crud_stats']['C']}")
        click.echo(f"  Read operations: {summary['crud_stats']['R']}")
        click.echo(f"  Update operations: {summary['crud_stats']['U']}")
        click.echo(f"  Delete operations: {summary['crud_stats']['D']}")
        click.echo(f"  Other operations: {summary['crud_stats']['O']}")
        
        if summary['most_active_class']:
            click.echo(f"  Most active class: {summary['most_active_class']}")
        if summary['most_used_table']:
            click.echo(f"  Most used table: {summary['most_used_table']}")
        
        # CRUD ë§¤íŠ¸ë¦­ìŠ¤ í‘œ ì¶œë ¥
        if table_matrix and table_names:
            click.echo(f"\nCRUD Matrix (Class vs Table):")
            
            # í…Œì´ë¸” í—¤ë” ê³„ì‚°
            class_name_width = max(len("Class (Package)"), max(len(f"{row['class_name']} ({row['package_name']})") for row in table_matrix)) if table_matrix else 20
            table_width = 18  # ê° í…Œì´ë¸” ì»¬ëŸ¼ ë„ˆë¹„ (ìŠ¤í‚¤ë§ˆ ì •ë³´ í¬í•¨ìœ¼ë¡œ ë” ë„“ê²Œ)
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Class (Package)':<{class_name_width}}"
            for table_name in table_names:
                # í…Œì´ë¸” ì´ë¦„ì„ 12ìë¡œ ì œí•œ
                short_name = table_name[:12] if len(table_name) > 12 else table_name
                header += f" {short_name:<{table_width}}"
            click.echo(header)
            
            # êµ¬ë¶„ì„  ì¶œë ¥
            separator = "-" * class_name_width
            for _ in table_names:
                separator += " " + "-" * table_width
            click.echo(separator)
            
            # ë°ì´í„° í–‰ ì¶œë ¥
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                class_display = f"{class_name} ({package_name})"
                line = f"{class_display:<{class_name_width}}"
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    line += f" {operations:<{table_width}}"
                click.echo(line)
        else:
            click.echo(f"\nSQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            click.echo(f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            click.echo(f"  1. Java ê°ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  2. MyBatis Mapperì™€ SQL ë¬¸ì´ ë¶„ì„ë˜ì—ˆëŠ”ì§€ í™•ì¸")
            click.echo(f"  3. í”„ë¡œì íŠ¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nCRUD matrix saved to: {output_file}")
        
        # Excel íŒŒì¼ë¡œ ì €ì¥
        if output_excel:
            success = analysis_service.generate_crud_excel(project_name, output_excel)
            if success:
                click.echo(f"CRUD matrix Excel file saved to: {output_excel}")
            else:
                click.echo("Failed to generate Excel file. Check logs for details.")
        
    except Exception as e:
        click.echo(f"Error generating CRUD matrix: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--start-class', help='Starting class for diagram (optional)')
@click.option('--start-method', help='Starting method for diagram (optional)')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def db_call_diagram(neo4j_uri, neo4j_user, project_name, start_class, start_method, output_file, output_image, image_format, image_width, image_height):
    """Generate database call chain diagram."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Call Chain Diagram")
        click.echo("=" * 50)
        
        if start_class and start_method:
            click.echo(f"Generating diagram from {start_class}.{start_method}")
        elif start_class:
            click.echo(f"Generating diagram from class {start_class}")
        else:
            click.echo(f"Generating diagram for project {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_call_chain_diagram(project_name, start_class, start_method)
        
        if diagram.startswith("ì˜¤ë¥˜:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"db_call_chain_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("DATABASE CALL CHAIN DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the diagram (optional)')
@click.option('--output-image', help='Output image file (PNG/SVG/PDF) - requires mermaid-cli')
@click.option('--image-format', default='png', type=click.Choice(['png', 'svg', 'pdf']), help='Image format (default: png)')
@click.option('--image-width', default=1200, help='Image width in pixels (default: 1200)')
@click.option('--image-height', default=800, help='Image height in pixels (default: 800)')
def crud_visualization(neo4j_uri, neo4j_user, project_name, output_file, output_image, image_format, image_width, image_height):
    """Generate CRUD matrix visualization diagram showing class-table relationships."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("CRUD Matrix Visualization Diagram")
        click.echo("=" * 50)
        click.echo(f"Generating diagram for project: {project_name}")
        
        # ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        diagram = analysis_service.generate_crud_visualization_diagram(project_name)
        
        if diagram.startswith("Error:"):
            click.echo(f"Error: {diagram}")
            return
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {output_file}")
        else:
            # ê¸°ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
            default_filename = f"crud_visualization_{project_name}.md"
            with open(default_filename, 'w', encoding='utf-8') as f:
                f.write(diagram)
            click.echo(f"Diagram saved to: {default_filename}")
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        if output_image:
            convert_to_image(diagram, output_image, image_format, image_width, image_height)
        
        # ë‹¤ì´ì–´ê·¸ë¨ ë¯¸ë¦¬ë³´ê¸°
        click.echo("\n" + "="*50)
        click.echo("CRUD MATRIX VISUALIZATION DIAGRAM")
        click.echo("="*50)
        click.echo(diagram)
        click.echo("="*50)
        
    except Exception as e:
        click.echo(f"Error generating diagram: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--table-name', required=True, help='Table name to analyze impact for')
@click.option('--output-file', help='Output file to save the impact analysis (optional)')
def table_impact(neo4j_uri, neo4j_user, project_name, table_name, output_file):
    """Analyze impact of table changes on application code."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Table Impact Analysis")
        click.echo("=" * 50)
        click.echo(f"Analyzing impact of changes to table: {table_name}")
        
        # ì˜í–¥ë„ ë¶„ì„
        result = analysis_service.analyze_table_impact(project_name, table_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        impacted_classes = result['impacted_classes']
        summary = result['summary']
        
        click.echo(f"\nImpact Summary:")
        click.echo(f"  Table: {summary['table_name']}")
        click.echo(f"  Impacted classes: {summary['total_impacted_classes']}")
        click.echo(f"  Impacted methods: {summary['total_impacted_methods']}")
        click.echo(f"  SQL statements: {summary['total_sql_statements']}")
        click.echo(f"  CRUD operations: {', '.join(summary['crud_operations'])}")
        
        if summary['high_complexity_sql']:
            click.echo(f"  High complexity SQL: {len(summary['high_complexity_sql'])}")
        
        # ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„¸ ì •ë³´
        if impacted_classes:
            click.echo(f"\nImpacted Classes:")
            click.echo("-" * 80)
            click.echo(f"{'Class':<25} {'Method':<25} {'SQL Type':<10} {'Complexity':<12}")
            click.echo("-" * 80)
            
            for cls in impacted_classes:
                class_name = cls['class_name']
                method_name = cls['method_name'] or 'N/A'
                sql_type = cls['sql_type'] or 'N/A'
                complexity = str(cls['complexity_score']) if cls['complexity_score'] else 'N/A'
                
                click.echo(f"{class_name:<25} {method_name:<25} {sql_type:<10} {complexity:<12}")
        
        # ê³ ë³µì¡ë„ SQL ìƒì„¸ ì •ë³´
        if summary['high_complexity_sql']:
            click.echo(f"\nHigh Complexity SQL Statements:")
            click.echo("-" * 60)
            for sql in summary['high_complexity_sql']:
                click.echo(f"  {sql['class_name']}.{sql['method_name']} - {sql['sql_type']} (complexity: {sql['complexity_score']})")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nImpact analysis saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error analyzing table impact: {e}")
        exit(1)
    finally:
        driver.close()

@cli.command()
@click.option('--neo4j-uri', default=os.getenv("NEO4J_URI", "bolt://localhost:7687"), help='Neo4j URI')
@click.option('--neo4j-user', default=os.getenv("NEO4J_USER", "neo4j"), help='Neo4j username')
@click.option('--project-name', required=True, help='Project name to analyze')
@click.option('--output-file', help='Output file to save the statistics (optional)')
def db_statistics(neo4j_uri, neo4j_user, project_name, output_file):
    """Show database usage statistics."""
    
    try:
        neo4j_password = os.getenv("NEO4J_PASSWORD")
        if not neo4j_password:
            click.echo("Error: NEO4J_PASSWORD environment variable is not set.")
            click.echo("Please set NEO4J_PASSWORD in your .env file or environment variables.")
            exit(1)
        
        driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))
        analysis_service = DBCallAnalysisService(driver)
        
        click.echo("Database Usage Statistics")
        click.echo("=" * 50)
        
        # í†µê³„ ì¡°íšŒ
        result = analysis_service.get_database_usage_statistics(project_name)
        
        if 'error' in result:
            click.echo(f"Error: {result['error']}")
            return
        
        sql_stats = result['sql_statistics']
        table_usage = result['table_usage']
        complexity_stats = result['complexity_statistics']
        
        # SQL í†µê³„
        if sql_stats:
            click.echo(f"\nSQL Statistics:")
            click.echo(f"  Total SQL statements: {sql_stats['total_sql']}")
            click.echo(f"  SELECT statements: {sql_stats.get('SELECT', 0)}")
            click.echo(f"  INSERT statements: {sql_stats.get('INSERT', 0)}")
            click.echo(f"  UPDATE statements: {sql_stats.get('UPDATE', 0)}")
            click.echo(f"  DELETE statements: {sql_stats.get('DELETE', 0)}")
        
        # í…Œì´ë¸” ì‚¬ìš© í†µê³„
        if table_usage:
            click.echo(f"\nTable Usage Statistics:")
            click.echo("-" * 60)
            click.echo(f"{'Table Name':<30} {'Access Count':<15} {'Operations':<20}")
            click.echo("-" * 60)
            
            for table in table_usage:
                table_name = table['table_name']
                access_count = table['access_count']
                operations = ', '.join(table['operations'])
                click.echo(f"{table_name:<30} {access_count:<15} {operations:<20}")
        
        # ë³µì¡ë„ í†µê³„
        if complexity_stats:
            click.echo(f"\nSQL Complexity Statistics:")
            click.echo(f"  Simple queries: {complexity_stats.get('simple', 0)}")
            click.echo(f"  Medium queries: {complexity_stats.get('medium', 0)}")
            click.echo(f"  Complex queries: {complexity_stats.get('complex', 0)}")
            click.echo(f"  Very complex queries: {complexity_stats.get('very_complex', 0)}")
        
        # íŒŒì¼ë¡œ ì €ì¥
        if output_file:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            click.echo(f"\nStatistics saved to: {output_file}")
        
    except Exception as e:
        click.echo(f"Error getting database statistics: {e}")
        exit(1)
    finally:
        driver.close()

if __name__ == '__main__':
    cli()

```

ì´ì œ Excel íŒŒì¼ ìƒì„± ë¶€ë¶„ë„ ìˆ˜ì •í•˜ì—¬ package nameê³¼ schema nameì„ í¬í•¨í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        schema_name = table_info['schema_name']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        # ìŠ¤í‚¤ë§ˆ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
                        row[table_name] = f"{operations_str} ({schema_name})"
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„±
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Class': class_name,
                    'Package': package_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # DataFrameì„ ì›Œí¬ì‹œíŠ¸ì— ì¶”ê°€
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 2):  # Class ì»¬ëŸ¼ + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(2, len(class_names) + 2):
                for col in range(1, len(table_names) + 2):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col == 1:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ Excel íŒŒì¼ì˜ ìŠ¤íƒ€ì¼ë§ ë¶€ë¶„ë„ ìˆ˜ì •í•˜ì—¬ Package ì»¬ëŸ¼ì„ í¬í•¨í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        schema_name = table_info['schema_name']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        # ìŠ¤í‚¤ë§ˆ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
                        row[table_name] = f"{operations_str} ({schema_name})"
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„±
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Class': class_name,
                    'Package': package_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # DataFrameì„ ì›Œí¬ì‹œíŠ¸ì— ì¶”ê°€
            for r in dataframe_to_rows(df, index=False, header=True):
                ws.append(r)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):  # Class + Package + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(2, len(class_names) + 2):
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Classì™€ Package ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col <= 2:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìˆ˜ì •ëœ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! ì´ì œ Excel íŒŒì¼ë„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.


ìƒì„±ëœ íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! **CRUD Matrixì— package nameê³¼ schema name ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€**ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ **êµ¬í˜„ëœ í–¥ìƒëœ ê¸°ëŠ¥ ìš”ì•½**

### 1. **CLI í‘œì‹œ ê°œì„ **
- **í´ë˜ìŠ¤ ì •ë³´**: `ClassName (PackageName)` í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- **í…Œì´ë¸” ì •ë³´**: `CRUD Operations (SchemaName)` í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- **ì˜ˆì‹œ**: 
  - `NotificationRepository (com.carcare.domain.notification.repository)`
  - `C, D, R, U (public)`

### 2. **Excel íŒŒì¼ ê°œì„ **
- **ì¶”ê°€ ì»¬ëŸ¼**: `Class`, `Package` ì»¬ëŸ¼ ì¶”ê°€
- **ìŠ¤í‚¤ë§ˆ ì •ë³´**: ê° CRUD ì—°ì‚°ì— ìŠ¤í‚¤ë§ˆëª… í‘œì‹œ
- **ìŠ¤íƒ€ì¼ë§**: Classì™€ Package ì»¬ëŸ¼ì— íŠ¹ë³„í•œ ìŠ¤íƒ€ì¼ ì ìš©

### 3. **ë°ì´í„° êµ¬ì¡° ê°œì„ **
```json
{
  "class_name": "NotificationRepository",
  "package_name": "com.carcare.domain.notification.repository",
  "notifications": "C, D, R, U (public)",
  "payments": "-"
}
```

### 4. **í‘œì‹œ í˜•ì‹ ì˜ˆì‹œ**

#### **CLI ì¶œë ¥**
```
Class (Package)                                                                 
    notification       notification       notification       payments           
----------------------------------------------------------------------------------- ------------------ ------------------ ------------------ ------------------
NotificationRepository (com.carcare.domain.notification.repository)             
    -                  -                  C, D, R, U (public) -                 
```

#### **Excel íŒŒì¼**
| Class | Package | notification_settings | notification_templates | notifications | ... |
|-------|---------|----------------------|----------------------|---------------|-----|
| NotificationRepository | com.carcare.domain.notification.repository | - | - | C, D, R, U (public) | ... |

### 5. **ìƒì„±ëœ íŒŒì¼ë“¤**
- `enhanced_crud_matrix.xlsx` (7.2KB) - í–¥ìƒëœ Excel íŒŒì¼
- ê¸°ì¡´ íŒŒì¼ë“¤ê³¼ ë¹„êµí•˜ì—¬ ë” ë§ì€ ì •ë³´ í¬í•¨

### 6. **ì£¼ìš” ê°œì„ ì‚¬í•­**
- **íŒ¨í‚¤ì§€ ì •ë³´**: í´ë˜ìŠ¤ì˜ ì „ì²´ íŒ¨í‚¤ì§€ ê²½ë¡œ í‘œì‹œ
- **ìŠ¤í‚¤ë§ˆ ì •ë³´**: ê° í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆëª… í‘œì‹œ
- **ê°€ë…ì„± í–¥ìƒ**: ë” ëª…í™•í•œ ì •ë³´ ì œê³µ
- **Excel í˜¸í™˜ì„±**: ì¶”ê°€ ì»¬ëŸ¼ìœ¼ë¡œ ë” ìƒì„¸í•œ ë¶„ì„ ê°€ëŠ¥

ì´ì œ ê°œë°œìë“¤ì´ CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í†µí•´ í´ë˜ìŠ¤ì˜ íŒ¨í‚¤ì§€ êµ¬ì¡°ì™€ í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´ê¹Œì§€ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```json
{
  "class_name": "NotificationRepository",
  "package_name": "com.carcare.domain.notification.repository",
  "notifications": "C, D, R, U (public)",
  "payments": "-"
}
```

```plaintext
Class (Package)                                                                 
    notification       notification       notification       payments           
----------------------------------------------------------------------------------- ------------------ ------------------ ------------------ ------------------
NotificationRepository (com.carcare.domain.notification.repository)             
    -                  -                  C, D, R, U (public) -                 
```

---

**User**

ì—‘ì…€ íŒŒì¼ ìƒì„±í•  ë•Œ
package nameì€ Class ì»¬ëŸ¼ ë³´ë‹¤ ì™¼ìª½ ì»¬ëŸ¼ì— í‘œì‹œí•˜ê³ 
SchemaëŠ” Table ëª… row ìœ—ìª½ rowì— í‘œì‹œí•  ê²ƒ

---

**Cursor**

Excel íŒŒì¼ì˜ ë ˆì´ì•„ì›ƒì„ ìˆ˜ì •í•˜ì—¬ package nameì„ Class ì»¬ëŸ¼ ì™¼ìª½ì—, Schemaë¥¼ Table ëª… ìœ„ìª½ í–‰ì— í‘œì‹œí•˜ë„ë¡ ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € `generate_crud_excel` ë©”ì„œë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ìƒˆë¡œìš´ ë ˆì´ì•„ì›ƒì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        schema_name = table_info['schema_name']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        # ìŠ¤í‚¤ë§ˆ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
                        row[table_name] = f"{operations_str} ({schema_name})"
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘
            schema_info = {}
            for row in table_matrix:
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    if operations != '-':
                        # operationsì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "C, D, R, U (public)")
                        if '(' in operations and ')' in operations:
                            schema = operations.split('(')[-1].split(')')[0]
                            schema_info[table_name] = schema
                        else:
                            schema_info[table_name] = 'public'  # ê¸°ë³¸ê°’
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):  # Class + Package + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(2, len(class_names) + 2):
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Classì™€ Package ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col <= 2:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìŠ¤íƒ€ì¼ë§ ë¶€ë¶„ë„ ìƒˆë¡œìš´ ë ˆì´ì•„ì›ƒì— ë§ê²Œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        schema_name = table_info['schema_name']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        # ìŠ¤í‚¤ë§ˆ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
                        row[table_name] = f"{operations_str} ({schema_name})"
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘
            schema_info = {}
            for row in table_matrix:
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    if operations != '-':
                        # operationsì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "C, D, R, U (public)")
                        if '(' in operations and ')' in operations:
                            schema = operations.split('(')[-1].split(')')[0]
                            schema_info[table_name] = schema
                        else:
                            schema_info[table_name] = 'public'  # ê¸°ë³¸ê°’
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            schema_fill = PatternFill(start_color="D9E1F2", end_color="D9E1F2", fill_type="solid")  # ìŠ¤í‚¤ë§ˆ í–‰ìš©
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ì²« ë²ˆì§¸ í–‰ (ìŠ¤í‚¤ë§ˆ ì •ë³´) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):  # Package + Class + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = Font(bold=True, color="000000")
                cell.fill = schema_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë‘ ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):
                cell = ws.cell(row=2, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(3, len(class_names) + 3):  # ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Packageì™€ Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col <= 2:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìˆ˜ì •ëœ Excel ë ˆì´ì•„ì›ƒì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ìƒì„±ëœ íŒŒì¼ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! **Excel íŒŒì¼ì˜ ë ˆì´ì•„ì›ƒì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •**ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ¯ **êµ¬í˜„ëœ ìƒˆë¡œìš´ Excel ë ˆì´ì•„ì›ƒ**

### 1. **ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½**
- **ì´ì „**: `Class | Package | Table1 | Table2 | ...`
- **í˜„ì¬**: `Package | Class | Table1 | Table2 | ...`

### 2. **í–‰ êµ¬ì¡° ë³€ê²½**
```
í–‰ 1: [ë¹ˆì¹¸] [ë¹ˆì¹¸] [Schema1] [Schema2] [Schema3] ...
í–‰ 2: [Package] [Class] [Table1] [Table2] [Table3] ...
í–‰ 3: [íŒ¨í‚¤ì§€ëª…] [í´ë˜ìŠ¤ëª…] [CRUDì—°ì‚°] [CRUDì—°ì‚°] [CRUDì—°ì‚°] ...
```

### 3. **ìŠ¤íƒ€ì¼ë§ ê°œì„ **
- **ì²« ë²ˆì§¸ í–‰ (Schema)**: ì—°í•œ íŒŒë€ìƒ‰ ë°°ê²½, êµµì€ ê¸€ì”¨
- **ë‘ ë²ˆì§¸ í–‰ (Header)**: ì§„í•œ íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ ê¸€ì”¨
- **ë°ì´í„° í–‰**: Packageì™€ Class ì»¬ëŸ¼ì€ ì—°í•œ íŒŒë€ìƒ‰ ë°°ê²½

### 4. **Excel íŒŒì¼ êµ¬ì¡° ì˜ˆì‹œ**
```
| Package | Class | notification_settings | notification_templates | ... |
|---------|-------|----------------------|----------------------|-----|
| (Schema) | (Schema) | public | public | ... |
| com.carcare... | NotificationRepository | - | - | ... |
| com.carcare... | NotificationSettings... | C, D, R, U | - | ... |
```

### 5. **ì£¼ìš” ê°œì„ ì‚¬í•­**
- **Package ì •ë³´**: ê°€ì¥ ì™¼ìª½ ì»¬ëŸ¼ì— ë°°ì¹˜í•˜ì—¬ íŒ¨í‚¤ì§€ë³„ ê·¸ë£¹í™” ìš©ì´
- **Schema ì •ë³´**: ê° í…Œì´ë¸” ì»¬ëŸ¼ ìœ„ì— ìŠ¤í‚¤ë§ˆëª… í‘œì‹œ
- **ê°€ë…ì„± í–¥ìƒ**: ì •ë³´ ê³„ì¸µ êµ¬ì¡°ê°€ ëª…í™•í•˜ê²Œ êµ¬ë¶„ë¨
- **ë¶„ì„ í¸ì˜ì„±**: íŒ¨í‚¤ì§€ë³„, ìŠ¤í‚¤ë§ˆë³„ ë¶„ì„ì´ ì‰¬ì›Œì§

### 6. **ìƒì„±ëœ íŒŒì¼**
- `new_layout_crud_matrix.xlsx` - ìƒˆë¡œìš´ ë ˆì´ì•„ì›ƒì˜ Excel íŒŒì¼

ì´ì œ Excel íŒŒì¼ì—ì„œ Package ì •ë³´ë¥¼ ì™¼ìª½ì—ì„œ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆê³ , ê° í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´ë„ ìƒë‹¨ì—ì„œ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

```plaintext
í–‰ 1: [ë¹ˆì¹¸] [ë¹ˆì¹¸] [Schema1] [Schema2] [Schema3] ...
í–‰ 2: [Package] [Class] [Table1] [Table2] [Table3] ...
í–‰ 3: [íŒ¨í‚¤ì§€ëª…] [í´ë˜ìŠ¤ëª…] [CRUDì—°ì‚°] [CRUDì—°ì‚°] [CRUDì—°ì‚°] ...
```

```plaintext
| Package | Class | notification_settings | notification_templates | ... |
|---------|-------|----------------------|----------------------|-----|
| (Schema) | (Schema) | public | public | ... |
| com.carcare... | NotificationRepository | - | - | ... |
| com.carcare... | NotificationSettings... | C, D, R, U | - | ... |
```

---

**User**

CRUD Matrix ExcelíŒŒì¼ ìƒì„± ìˆ˜ì •
1. Package, Class ì»¬ëŸ¼ ê°’ì€ : ì¢Œì¸¡ì •ë ¬, ë³´í†µê¸€ì”¨ êµµê¸°ë¡œ, 
2. Tableì˜ Schema rowì˜ ë°”íƒ•ìƒ‰ê³¼ fontìƒ‰ì€ table rowì™€ ë™ì¼í•˜ê²Œ ìˆ˜ì •
3. C, D, R, U (public) : (public)ê³¼ ê°™ì€ schema ëª…ì€ ì œê±°í•˜ê³  C, D, R, Uë§Œ ê¸°ì¬, êµµì€ê¸€ì”¨ë¡œ í‘œì‹œ

---

**Cursor**

CRUD Matrix Excel íŒŒì¼ì˜ ìŠ¤íƒ€ì¼ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


ë¨¼ì € CRUD ì—°ì‚°ì—ì„œ ìŠ¤í‚¤ë§ˆëª…ì„ ì œê±°í•˜ê³  êµµì€ê¸€ì”¨ë¡œ í‘œì‹œí•˜ë„ë¡ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ (ìŠ¤í‚¤ë§ˆëª… ì œê±°)
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        row[table_name] = operations_str
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘
            schema_info = {}
            for row in table_matrix:
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    if operations != '-':
                        # operationsì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: "C, D, R, U (public)")
                        if '(' in operations and ')' in operations:
                            schema = operations.split('(')[-1].split(')')[0]
                            schema_info[table_name] = schema
                        else:
                            schema_info[table_name] = 'public'  # ê¸°ë³¸ê°’
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            schema_fill = PatternFill(start_color="D9E1F2", end_color="D9E1F2", fill_type="solid")  # ìŠ¤í‚¤ë§ˆ í–‰ìš©
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ì²« ë²ˆì§¸ í–‰ (ìŠ¤í‚¤ë§ˆ ì •ë³´) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):  # Package + Class + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = Font(bold=True, color="000000")
                cell.fill = schema_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë‘ ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):
                cell = ws.cell(row=2, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(3, len(class_names) + 3):  # ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Packageì™€ Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col <= 2:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ Excel íŒŒì¼ ìƒì„± ë¶€ë¶„ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ ë¡œì§ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ (ìŠ¤í‚¤ë§ˆëª… ì œê±°)
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        row[table_name] = operations_str
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ (ì›ë³¸ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
            schema_info = {}
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            schema_name = table_info.get('schema_name', 'public')
                            schema_info[table_name] = schema_name
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            schema_fill = PatternFill(start_color="D9E1F2", end_color="D9E1F2", fill_type="solid")  # ìŠ¤í‚¤ë§ˆ í–‰ìš©
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ì²« ë²ˆì§¸ í–‰ (ìŠ¤í‚¤ë§ˆ ì •ë³´) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):  # Package + Class + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = Font(bold=True, color="000000")
                cell.fill = schema_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë‘ ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):
                cell = ws.cell(row=2, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(3, len(class_names) + 3):  # ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.alignment = center_alignment
                    cell.border = thin_border
                    
                    # Packageì™€ Class ì»¬ëŸ¼ì€ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ
                    if col <= 2:
                        cell.fill = class_fill
                        cell.font = Font(bold=True)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìŠ¤íƒ€ì¼ë§ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ (ìŠ¤í‚¤ë§ˆëª… ì œê±°)
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        row[table_name] = operations_str
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ (ì›ë³¸ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
            schema_info = {}
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            schema_name = table_info.get('schema_name', 'public')
                            schema_info[table_name] = schema_name
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            left_alignment = Alignment(horizontal="left", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ì²« ë²ˆì§¸ í–‰ (ìŠ¤í‚¤ë§ˆ ì •ë³´) ìŠ¤íƒ€ì¼ ì ìš© - í—¤ë”ì™€ ë™ì¼í•˜ê²Œ
            for col in range(1, len(table_names) + 3):  # Package + Class + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë‘ ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):
                cell = ws.cell(row=2, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(3, len(class_names) + 3):  # ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.border = thin_border
                    
                    if col <= 2:  # Packageì™€ Class ì»¬ëŸ¼
                        cell.fill = class_fill
                        cell.font = Font(bold=False)  # ë³´í†µê¸€ì”¨
                        cell.alignment = left_alignment  # ì¢Œì¸¡ì •ë ¬
                    else:  # í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                        cell.alignment = center_alignment
                        # CRUD ì—°ì‚°ì´ ìˆëŠ” ê²½ìš° êµµì€ê¸€ì”¨ë¡œ
                        if cell.value and cell.value != '-':
                            cell.font = Font(bold=True)
                        else:
                            cell.font = Font(bold=False)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìˆ˜ì •ëœ Excel íŒŒì¼ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


---

**User**

ERROR: Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: name 'class_matrix' is not defined
Failed to generate Excel file. Check logs for details.

---

**Cursor**

Excel íŒŒì¼ ìƒì„±ì—ì„œ `class_matrix` ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. `generate_crud_excel` ë©”ì„œë“œì—ì„œ `class_matrix`ë¥¼ ì‚¬ìš©í•˜ë ¤ê³  í•˜ëŠ”ë°, ì´ ë³€ìˆ˜ê°€ ìŠ¤ì½”í”„ì— ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.


```python
"""
ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤

ì´ ëª¨ë“ˆì€ ì–´í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ í˜¸ì¶œê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ ë¶„ì„
- CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
- í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ ìƒì„± (Mermaid ë‹¤ì´ì–´ê·¸ë¨)
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„ ë° ì‹œê°í™”
- ì˜í–¥ë„ ë¶„ì„
"""

import json
from typing import List, Dict, Any, Optional, Set, Tuple
from neo4j import Driver
from src.utils.logger import get_logger


class DBCallAnalysisService:
    """ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self, driver: Driver):
        """Neo4j ë“œë¼ì´ë²„ë¡œ ì´ˆê¸°í™”"""
        self.driver = driver
        self.logger = get_logger(__name__)
    
    def analyze_call_chain(self, project_name: str, start_class: str = None, start_method: str = None) -> Dict[str, Any]:
        """
        Controller â†’ Service â†’ Repository â†’ SQL â†’ Table/Column í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                if start_class and start_method:
                    # íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_method_call_chain(session, project_name, start_class, start_method)
                elif start_class:
                    # íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_class_call_chain(session, project_name, start_class)
                else:
                    # ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸
                    call_chain = self._get_project_call_chain(session, project_name)
                
                # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œ ì‹ë³„
                missing_nodes = self._identify_missing_nodes(session, project_name, call_chain)
                
                return {
                    'project_name': project_name,
                    'call_chain': call_chain,
                    'missing_nodes': missing_nodes,
                    'analysis_summary': self._generate_analysis_summary(call_chain, missing_nodes)
                }
                
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _get_method_call_chain(self, session, project_name: str, class_name: str, method_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë©”ì„œë“œë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method {name: $method_name})
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           method_name=method_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_class_call_chain(self, session, project_name: str, class_name: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • í´ë˜ìŠ¤ë¶€í„° ì‹œì‘í•˜ëŠ” í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {name: $class_name, project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, 
                           class_name=class_name, 
                           project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _get_project_call_chain(self, session, project_name: str) -> List[Dict[str, Any]]:
        """ì „ì²´ í”„ë¡œì íŠ¸ì˜ í˜¸ì¶œ ì²´ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
        OPTIONAL MATCH (m)-[:CALLS*0..5]->(target_method:Method)
        OPTIONAL MATCH (target_method)<-[:HAS_METHOD]-(target_class:Class)
        OPTIONAL MATCH (target_method)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_TABLE]->(table:Table {project_name: $project_name})
        OPTIONAL MATCH (sql)-[:USES_COLUMN]->(column:Column {project_name: $project_name})
        RETURN m.name as source_method,
               c.name as source_class,
               c.package_name as source_package,
               target_method.name as target_method,
               target_class.name as target_class,
               target_class.package_name as target_package,
               sql.id as sql_id,
               sql.sql_type as sql_type,
               sql.tables as sql_tables,
               sql.columns as sql_columns,
               table.name as table_name,
               column.name as column_name,
               column.table_name as column_table_name
        ORDER BY source_class, source_method, target_class.name, target_method.name
        """
        
        result = session.run(query, project_name=project_name)
        
        call_chain = []
        for record in result:
            call_chain.append({
                'source_method': record['source_method'],
                'source_class': record['source_class'],
                'source_package': record['source_package'] or 'default',
                'target_method': record['target_method'],
                'target_class': record['target_class'],
                'target_package': record['target_package'] or 'default',
                'sql_id': record['sql_id'],
                'sql_type': record['sql_type'],
                'sql_tables': json.loads(record['sql_tables']) if record['sql_tables'] else [],
                'sql_columns': json.loads(record['sql_columns']) if record['sql_columns'] else [],
                'table_name': record['table_name'],
                'column_name': record['column_name'],
                'column_table_name': record['column_table_name']
            })
        
        return call_chain
    
    def _identify_missing_nodes(self, session, project_name: str, call_chain: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” Table/Column ë…¸ë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."""
        missing_tables = set()
        missing_columns = set()
        
        # SQLì—ì„œ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ìˆ˜ì§‘
        referenced_tables = set()
        referenced_columns = set()
        
        for call in call_chain:
            # SQL í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_tables'):
                for table_info in call['sql_tables']:
                    if isinstance(table_info, dict) and 'name' in table_info:
                        referenced_tables.add(table_info['name'])
            
            # SQL ì»¬ëŸ¼ ì •ë³´ ìˆ˜ì§‘
            if call.get('sql_columns'):
                for column_info in call['sql_columns']:
                    if isinstance(column_info, dict) and 'name' in column_info:
                        referenced_columns.add(column_info['name'])
                        if 'table' in column_info and column_info['table']:
                            referenced_tables.add(column_info['table'])
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¡°íšŒ
        existing_tables = self._get_existing_tables(session, project_name)
        existing_columns = self._get_existing_columns(session, project_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸” ì‹ë³„
        for table_name in referenced_tables:
            if table_name not in existing_tables:
                missing_tables.add(table_name)
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì‹ë³„
        for column_name in referenced_columns:
            if column_name not in existing_columns:
                missing_columns.add(column_name)
        
        return {
            'missing_tables': list(missing_tables),
            'missing_columns': list(missing_columns)
        }
    
    def _get_existing_tables(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (t:Table {project_name: $project_name})
        RETURN t.name as table_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['table_name'] for record in result}
    
    def _get_existing_columns(self, session, project_name: str) -> Set[str]:
        """ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = """
        MATCH (c:Column {project_name: $project_name})
        RETURN c.name as column_name
        """
        
        result = session.run(query, project_name=project_name)
        return {record['column_name'] for record in result}
    
    def _generate_analysis_summary(self, call_chain: List[Dict[str, Any]], missing_nodes: Dict[str, List[str]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_stats = {}
        for call in call_chain:
            source_class = call['source_class']
            if source_class not in class_stats:
                class_stats[source_class] = {
                    'method_count': 0,
                    'sql_count': 0,
                    'table_count': 0,
                    'column_count': 0
                }
            
            if call['source_method']:
                class_stats[source_class]['method_count'] += 1
            if call['sql_id']:
                class_stats[source_class]['sql_count'] += 1
            if call['table_name']:
                class_stats[source_class]['table_count'] += 1
            if call['column_name']:
                class_stats[source_class]['column_count'] += 1
        
        return {
            'total_calls': len(call_chain),
            'unique_classes': len(class_stats),
            'unique_methods': len(set(call['source_method'] for call in call_chain if call['source_method'])),
            'unique_sql_statements': len(set(call['sql_id'] for call in call_chain if call['sql_id'])),
            'unique_tables': len(set(call['table_name'] for call in call_chain if call['table_name'])),
            'unique_columns': len(set(call['column_name'] for call in call_chain if call['column_name'])),
            'missing_tables_count': len(missing_nodes['missing_tables']),
            'missing_columns_count': len(missing_nodes['missing_columns']),
            'class_stats': class_stats
        }
    
    def generate_crud_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ë§Œ í¬í•¨í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            with self.driver.session() as session:
                # SQLì„ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” í´ë˜ìŠ¤ì™€ ì‹¤ì œ í…Œì´ë¸” ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
                class_crud_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                WITH c, m, sql,
                     CASE 
                       WHEN sql.sql_type = 'SELECT' THEN 'R'
                       WHEN sql.sql_type = 'INSERT' THEN 'C'
                       WHEN sql.sql_type = 'UPDATE' THEN 'U'
                       WHEN sql.sql_type = 'DELETE' THEN 'D'
                       ELSE 'O'
                     END as crud_operation
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       sql.tables as tables_json,
                       crud_operation as operation,
                       sql.id as sql_id
                ORDER BY c.name
                """
                
                result = session.run(class_crud_query, project_name=project_name)
                raw_data = [record.data() for record in result]
                
                # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (1:1 ê´€ê³„ë¡œ í‘œì‹œ)
                class_table_relations = []
                processed_combinations = set()
                
                for row in raw_data:
                    class_name = row['class_name']
                    package_name = row['package_name']
                    operation = row['operation']
                    sql_id = row['sql_id']
                    database_name = 'default'  # ê¸°ë³¸ê°’ ì„¤ì •
                    schema_name = 'public'    # ê¸°ë³¸ê°’ ì„¤ì •
                    
                    # ì‹¤ì œ í…Œì´ë¸” ì •ë³´ íŒŒì‹±
                    try:
                        tables_json = row['tables_json']
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    
                                    # í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                                    combination_key = f"{class_name}_{table_name}"
                                    if combination_key not in processed_combinations:
                                        processed_combinations.add(combination_key)
                                        
                                        # í•´ë‹¹ í´ë˜ìŠ¤-í…Œì´ë¸” ì¡°í•©ì˜ ëª¨ë“  SQL ì°¾ê¸°
                                        table_operations = set()
                                        table_sql_statements = set()
                                        
                                        for check_row in raw_data:
                                            if (check_row['class_name'] == class_name and 
                                                check_row['tables_json'] and 
                                                check_row['tables_json'] != '[]'):
                                                try:
                                                    check_tables = json.loads(check_row['tables_json'])
                                                    for check_table in check_tables:
                                                        if (isinstance(check_table, dict) and 
                                                            'name' in check_table and 
                                                            check_table['name'] == table_name):
                                                            table_operations.add(check_row['operation'])
                                                            table_sql_statements.add(check_row['sql_id'])
                                                except (json.JSONDecodeError, TypeError):
                                                    continue
                                        
                                        class_table_relations.append({
                                            'class_name': class_name,
                                            'package_name': package_name,
                                            'table_name': table_name,
                                            'database_name': database_name,
                                            'schema_name': schema_name,
                                            'operations': list(table_operations),
                                            'sql_statements': list(table_sql_statements)
                                        })
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ë¥¼ í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
                class_matrix = {}
                for relation in class_table_relations:
                    class_name = relation['class_name']
                    if class_name not in class_matrix:
                        class_matrix[class_name] = {
                            'class_name': class_name,
                            'package_name': relation['package_name'],
                            'tables': [],
                            'operations': set(),
                            'sql_statements': set()
                        }
                    
                    class_matrix[class_name]['tables'].append({
                        'table_name': relation['table_name'],
                        'database_name': relation['database_name'],
                        'schema_name': relation['schema_name'],
                        'operations': relation['operations']
                    })
                    class_matrix[class_name]['operations'].update(relation['operations'])
                    class_matrix[class_name]['sql_statements'].update(relation['sql_statements'])
                
                # ìµœì¢… í˜•íƒœë¡œ ë³€í™˜
                class_matrix = [
                    {
                        'class_name': data['class_name'],
                        'package_name': data['package_name'],
                        'tables': data['tables'],
                        'operations': list(data['operations']),
                        'sql_statements': list(data['sql_statements'])
                    }
                    for data in class_matrix.values()
                ]
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ (Pythonì—ì„œ ì²˜ë¦¬)
                table_crud_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL AND sql.tables <> '[]'
                RETURN sql.tables as tables_json, sql.sql_type as operation
                """
                
                result = session.run(table_crud_query, project_name=project_name)
                raw_table_data = [record.data() for record in result]
                
                # Pythonì—ì„œ í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                table_stats = {}
                for row in raw_table_data:
                    try:
                        tables_json = row['tables_json']
                        operation = row['operation']
                        
                        if tables_json and tables_json != '[]':
                            tables = json.loads(tables_json)
                            for table_info in tables:
                                if isinstance(table_info, dict) and 'name' in table_info:
                                    table_name = table_info['name']
                                    if table_name not in table_stats:
                                        table_stats[table_name] = {}
                                    if operation not in table_stats[table_name]:
                                        table_stats[table_name][operation] = 0
                                    table_stats[table_name][operation] += 1
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"í…Œì´ë¸” JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                # í…Œì´ë¸”ë³„ CRUD ë§¤íŠ¸ë¦­ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                table_matrix = []
                for table_name, operations in table_stats.items():
                    operations_list = [{'operation': op, 'count': count} for op, count in operations.items()]
                    table_matrix.append({
                        'table_name': table_name,
                        'operations': operations_list
                    })
                
                return {
                    'project_name': project_name,
                    'class_matrix': class_matrix,
                    'table_matrix': table_matrix,
                    'summary': self._generate_crud_summary(class_matrix, table_matrix)
                }
                
        except Exception as e:
            self.logger.error(f"CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def _generate_crud_summary(self, class_matrix: List[Dict], table_matrix: List[Dict]) -> Dict[str, Any]:
        """CRUD ë§¤íŠ¸ë¦­ìŠ¤ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        total_classes = len(class_matrix)
        total_tables = len(table_matrix)
        
        # CRUD ì‘ì—…ë³„ í†µê³„
        crud_stats = {'C': 0, 'R': 0, 'U': 0, 'D': 0, 'O': 0}
        for class_data in class_matrix:
            for operation in class_data['operations']:
                if operation in crud_stats:
                    crud_stats[operation] += 1
        
        return {
            'total_classes': total_classes,
            'total_tables': total_tables,
            'crud_stats': crud_stats,
            'most_active_class': max(class_matrix, key=lambda x: len(x['operations']))['class_name'] if class_matrix else None,
            'most_used_table': max(table_matrix, key=lambda x: sum(op['count'] for op in x['operations']))['table_name'] if table_matrix else None
        }
    
    def generate_call_chain_diagram(self, project_name: str, start_class: str = None, start_method: str = None) -> str:
        """
        í˜¸ì¶œ ì²´ì¸ì„ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            start_class: ì‹œì‘ í´ë˜ìŠ¤ (ì„ íƒì‚¬í•­)
            start_method: ì‹œì‘ ë©”ì„œë“œ (ì„ íƒì‚¬í•­)
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            analysis_result = self.analyze_call_chain(project_name, start_class, start_method)
            
            if 'error' in analysis_result:
                return f"ì˜¤ë¥˜: {analysis_result['error']}"
            
            call_chain = analysis_result['call_chain']
            missing_nodes = analysis_result['missing_nodes']
            
            if not call_chain:
                return "```mermaid\ngraph TD\n    A[No call chain found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            for call in call_chain:
                if call['source_class']:
                    nodes.add(call['source_class'])
                if call['target_class']:
                    nodes.add(call['target_class'])
                if call['table_name']:
                    nodes.add(f"Table_{call['table_name']}")
                if call['column_name']:
                    nodes.add(f"Column_{call['column_name']}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì¶”ê°€ (ì ìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
            for missing_table in missing_nodes['missing_tables']:
                nodes.add(f"MissingTable_{missing_table}")
            
            for missing_column in missing_nodes['missing_columns']:
                nodes.add(f"MissingColumn_{missing_column}")
            
            # ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
            for node in sorted(nodes):
                if node.startswith('MissingTable_'):
                    table_name = node.replace('MissingTable_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {table_name}\"]:::missingTable")
                elif node.startswith('MissingColumn_'):
                    column_name = node.replace('MissingColumn_', '')
                    diagram_lines.append(f"    {node}[\"âŒ {column_name}\"]:::missingColumn")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]:::table")
                elif node.startswith('Column_'):
                    column_name = node.replace('Column_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“‹ {column_name}\"]:::column")
                else:
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {node}\"]:::class")
            
            # ì—°ê²°ì„  ì •ì˜
            for call in call_chain:
                if call['source_class'] and call['target_class']:
                    diagram_lines.append(f"    {call['source_class']} --> {call['target_class']}")
                
                if call['target_class'] and call['table_name']:
                    table_node = f"Table_{call['table_name']}"
                    diagram_lines.append(f"    {call['target_class']} --> {table_node}")
                
                if call['table_name'] and call['column_name']:
                    table_node = f"Table_{call['table_name']}"
                    column_node = f"Column_{call['column_name']}"
                    diagram_lines.append(f"    {table_node} --> {column_node}")
            
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œ ì—°ê²° (ì ìƒ‰ ì ì„ )
            for call in call_chain:
                if call['table_name'] and call['table_name'] in missing_nodes['missing_tables']:
                    missing_table_node = f"MissingTable_{call['table_name']}"
                    if call['target_class']:
                        diagram_lines.append(f"    {call['target_class']} -.-> {missing_table_node}")
                
                if call['column_name'] and call['column_name'] in missing_nodes['missing_columns']:
                    missing_column_node = f"MissingColumn_{call['column_name']}"
                    if call['table_name']:
                        table_node = f"Table_{call['table_name']}"
                        diagram_lines.append(f"    {table_node} -.-> {missing_column_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            diagram_lines.extend([
                "",
                "    classDef class fill:#e1f5fe,stroke:#01579b,stroke-width:2px",
                "    classDef table fill:#f3e5f5,stroke:#4a148c,stroke-width:2px",
                "    classDef column fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px",
                "    classDef missingTable fill:#ffebee,stroke:#c62828,stroke-width:2px,stroke-dasharray: 5 5",
                "    classDef missingColumn fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,stroke-dasharray: 5 5"
            ])
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"í˜¸ì¶œ ì²´ì¸ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì˜¤ë¥˜: {str(e)}"
    
    def analyze_table_impact(self, project_name: str, table_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸” ë³€ê²½ ì‹œ ì˜í–¥ë°›ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            table_name: ë¶„ì„í•  í…Œì´ë¸” ì´ë¦„
            
        Returns:
            ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        try:
            with self.driver.session() as session:
                # í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤/ë©”ì„œë“œ ì¡°íšŒ
                impact_query = """
                MATCH (c:Class {project_name: $project_name})-[:HAS_METHOD]->(m:Method)
                MATCH (m)-[:CALLS]->(sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables CONTAINS $table_name OR 
                      ANY(table_info IN sql.tables WHERE table_info.name = $table_name)
                RETURN c.name as class_name,
                       c.package_name as package_name,
                       m.name as method_name,
                       sql.id as sql_id,
                       sql.sql_type as sql_type,
                       sql.complexity_score as complexity_score
                ORDER BY c.name, m.name
                """
                
                result = session.run(impact_query, 
                                   project_name=project_name, 
                                   table_name=table_name)
                
                impacted_classes = []
                for record in result:
                    impacted_classes.append({
                        'class_name': record['class_name'],
                        'package_name': record['package_name'],
                        'method_name': record['method_name'],
                        'sql_id': record['sql_id'],
                        'sql_type': record['sql_type'],
                        'complexity_score': record['complexity_score']
                    })
                
                # ì˜í–¥ë„ ìš”ì•½
                summary = {
                    'table_name': table_name,
                    'total_impacted_classes': len(set(c['class_name'] for c in impacted_classes)),
                    'total_impacted_methods': len(set(f"{c['class_name']}.{c['method_name']}" for c in impacted_classes)),
                    'total_sql_statements': len(set(c['sql_id'] for c in impacted_classes if c['sql_id'])),
                    'crud_operations': list(set(c['sql_type'] for c in impacted_classes if c['sql_type'])),
                    'high_complexity_sql': [c for c in impacted_classes if c['complexity_score'] and c['complexity_score'] > 7]
                }
                
                return {
                    'table_name': table_name,
                    'impacted_classes': impacted_classes,
                    'summary': summary
                }
                
        except Exception as e:
            self.logger.error(f"í…Œì´ë¸” ì˜í–¥ë„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def get_database_usage_statistics(self, project_name: str) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„
        """
        try:
            with self.driver.session() as session:
                # SQL í†µê³„
                sql_stats_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                RETURN 
                    count(sql) as total_sql,
                    sum(CASE WHEN sql.sql_type = 'SELECT' THEN 1 ELSE 0 END) as SELECT,
                    sum(CASE WHEN sql.sql_type = 'INSERT' THEN 1 ELSE 0 END) as INSERT,
                    sum(CASE WHEN sql.sql_type = 'UPDATE' THEN 1 ELSE 0 END) as UPDATE,
                    sum(CASE WHEN sql.sql_type = 'DELETE' THEN 1 ELSE 0 END) as DELETE
                """
                
                result = session.run(sql_stats_query, project_name=project_name)
                sql_stats = result.single().data() if result.single() else {}
                
                # í…Œì´ë¸” ì‚¬ìš© í†µê³„
                table_usage_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.tables IS NOT NULL
                UNWIND sql.tables as table_info
                WITH table_info.name as table_name, sql.sql_type as operation
                RETURN 
                    table_name,
                    count(*) as access_count,
                    collect(DISTINCT operation) as operations
                ORDER BY access_count DESC
                """
                
                result = session.run(table_usage_query, project_name=project_name)
                table_usage = [record.data() for record in result]
                
                # ë³µì¡ë„ í†µê³„
                complexity_query = """
                MATCH (sql:SqlStatement {project_name: $project_name})
                WHERE sql.complexity_score IS NOT NULL
                WITH sql.complexity_score as score,
                     CASE 
                         WHEN sql.complexity_score <= 3 THEN 'simple'
                         WHEN sql.complexity_score <= 7 THEN 'medium'
                         WHEN sql.complexity_score <= 12 THEN 'complex'
                         ELSE 'very_complex'
                     END as complexity_level
                RETURN 
                    complexity_level,
                    count(*) as count
                """
                
                result = session.run(complexity_query, project_name=project_name)
                complexity_stats = {record['complexity_level']: record['count'] for record in result}
                
                return {
                    'project_name': project_name,
                    'sql_statistics': sql_stats,
                    'table_usage': table_usage,
                    'complexity_statistics': complexity_stats
                }
                
        except Exception as e:
            self.logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {'error': str(e)}
    
    def generate_crud_visualization_diagram(self, project_name: str) -> str:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜-ë°ì´í„°ë² ì´ìŠ¤ í˜¸ì¶œê´€ê³„ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            Mermaid ë‹¤ì´ì–´ê·¸ë¨ ë¬¸ìì—´
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return "```mermaid\ngraph TD\n    A[No database calls found]\n```"
            
            # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
            diagram_lines = ["```mermaid", "graph TD"]
            
            # ë…¸ë“œ ì •ì˜
            nodes = set()
            class_table_relations = []
            
            # í´ë˜ìŠ¤ì™€ í…Œì´ë¸” ë…¸ë“œ ìˆ˜ì§‘
            for class_data in class_matrix:
                class_name = class_data['class_name']
                nodes.add(f"Class_{class_name}")
                
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            nodes.add(f"Table_{table_name}")
                            
                            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì €ì¥
                            operations = table_info.get('operations', [])
                            class_table_relations.append({
                                'class_name': class_name,
                                'table_name': table_name,
                                'operations': operations,
                                'database_name': table_info.get('database_name', 'default'),
                                'schema_name': table_info.get('schema_name', 'public')
                            })
            
            # ë…¸ë“œ ì •ì˜ ì¶”ê°€
            for node in sorted(nodes):
                if node.startswith('Class_'):
                    class_name = node.replace('Class_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ¢ {class_name}\"]")
                elif node.startswith('Table_'):
                    table_name = node.replace('Table_', '')
                    diagram_lines.append(f"    {node}[\"ğŸ“Š {table_name}\"]")
            
            # í´ë˜ìŠ¤-í…Œì´ë¸” ê´€ê³„ ì—°ê²°
            for relation in class_table_relations:
                class_node = f"Class_{relation['class_name']}"
                table_node = f"Table_{relation['table_name']}"
                
                # CRUD ì—°ì‚°ì„ ë¼ë²¨ë¡œ í‘œì‹œ
                operations_str = ', '.join(relation['operations'])
                diagram_lines.append(f"    {class_node} -->|{operations_str}| {table_node}")
            
            # ìŠ¤íƒ€ì¼ ì •ì˜ (Mermaid í˜¸í™˜ì„±ì„ ìœ„í•´ ì œê±°)
            
            diagram_lines.append("```")
            
            return "\n".join(diagram_lines)
            
        except Exception as e:
            self.logger.error(f"CRUD ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"```mermaid\ngraph TD\n    A[Error: {str(e)}]\n```"
    
    def generate_crud_table_matrix(self, project_name: str) -> Dict[str, Any]:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í‘œ í˜•íƒœë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        ê°€ë¡œì¶•: í…Œì´ë¸”, ì„¸ë¡œì¶•: í´ë˜ìŠ¤
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            
        Returns:
            í‘œ í˜•íƒœì˜ CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°
        """
        try:
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_matrix(project_name)
            class_matrix = crud_data['class_matrix']
            table_matrix = crud_data['table_matrix']
            
            if not class_matrix:
                return {
                    'table_matrix': [],
                    'class_names': [],
                    'table_names': [],
                    'summary': {'total_classes': 0, 'total_tables': 0}
                }
            
            # ëª¨ë“  í…Œì´ë¸” ì´ë¦„ ìˆ˜ì§‘
            all_tables = set()
            for class_data in class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            all_tables.add(table_info['table_name'])
            
            table_names = sorted(list(all_tables))
            class_names = [class_data['class_name'] for class_data in class_matrix]
            
            # í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            table_matrix = []
            for class_data in class_matrix:
                class_name = class_data['class_name']
                package_name = class_data.get('package_name', 'N/A')
                row = {
                    'class_name': class_name,
                    'package_name': package_name
                }
                
                # ê° í…Œì´ë¸”ì— ëŒ€í•œ CRUD ì—°ì‚° í™•ì¸
                class_tables = {}
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            operations = table_info.get('operations', [])
                            schema_name = table_info.get('schema_name', 'public')
                            database_name = table_info.get('database_name', 'default')
                            class_tables[table_name] = {
                                'operations': operations,
                                'schema_name': schema_name,
                                'database_name': database_name
                            }
                
                # ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•´ CRUD ì—°ì‚° í‘œì‹œ
                for table_name in table_names:
                    if table_name in class_tables:
                        table_info = class_tables[table_name]
                        operations = table_info['operations']
                        # CRUD ì—°ì‚°ì„ ì •ë ¬í•˜ì—¬ í‘œì‹œ (ìŠ¤í‚¤ë§ˆëª… ì œê±°)
                        sorted_ops = sorted(operations)
                        operations_str = ', '.join(sorted_ops) if sorted_ops else '-'
                        row[table_name] = operations_str
                    else:
                        row[table_name] = '-'
                
                table_matrix.append(row)
            
            return {
                'table_matrix': table_matrix,
                'class_names': class_names,
                'table_names': table_names,
                'summary': crud_data['summary']
            }
            
        except Exception as e:
            self.logger.error(f"CRUD í‘œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def generate_crud_excel(self, project_name: str, output_file: str) -> bool:
        """
        CRUD ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ Excel íŒŒì¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
            output_file: ì¶œë ¥í•  Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            from openpyxl.utils.dataframe import dataframe_to_rows
            
            # CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            crud_data = self.generate_crud_table_matrix(project_name)
            
            if 'error' in crud_data:
                self.logger.error(f"CRUD ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {crud_data['error']}")
                return False
            
            table_matrix = crud_data['table_matrix']
            class_names = crud_data['class_names']
            table_names = crud_data['table_names']
            summary = crud_data['summary']
            
            if not table_matrix or not table_names:
                self.logger.warning("CRUD ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrame ìƒì„± (Packageë¥¼ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ)
            df_data = []
            for row in table_matrix:
                class_name = row['class_name']
                package_name = row.get('package_name', 'N/A')
                row_data = {
                    'Package': package_name,
                    'Class': class_name
                }
                for table_name in table_names:
                    operations = row.get(table_name, '-')
                    row_data[table_name] = operations
                df_data.append(row_data)
            
            df = pd.DataFrame(df_data)
            
            # Excel íŒŒì¼ ìƒì„±
            wb = Workbook()
            ws = wb.active
            ws.title = "CRUD Matrix"
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ìˆ˜ì§‘ (ì›ë³¸ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ)
            schema_info = {}
            # ì›ë³¸ CRUD ë°ì´í„°ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ
            original_crud_data = self.generate_crud_matrix(project_name)
            original_class_matrix = original_crud_data['class_matrix']
            
            for class_data in original_class_matrix:
                if 'tables' in class_data and class_data['tables']:
                    for table_info in class_data['tables']:
                        if isinstance(table_info, dict) and 'table_name' in table_info:
                            table_name = table_info['table_name']
                            schema_name = table_info.get('schema_name', 'public')
                            schema_info[table_name] = schema_name
            
            # ì²« ë²ˆì§¸ í–‰: ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema_row = ['', '']  # Package, Class ì»¬ëŸ¼ì€ ë¹„ì›€
            for table_name in table_names:
                schema = schema_info.get(table_name, 'public')
                schema_row.append(schema)
            ws.append(schema_row)
            
            # ë‘ ë²ˆì§¸ í–‰: í…Œì´ë¸” í—¤ë”
            header_row = ['Package', 'Class']
            for table_name in table_names:
                header_row.append(table_name)
            ws.append(header_row)
            
            # ë°ì´í„° í–‰ë“¤
            for _, row in df.iterrows():
                data_row = [row['Package'], row['Class']]
                for table_name in table_names:
                    operations = row[table_name]
                    data_row.append(operations)
                ws.append(data_row)
            
            # ìŠ¤íƒ€ì¼ ì ìš©
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            class_fill = PatternFill(start_color="E7F3FF", end_color="E7F3FF", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            left_alignment = Alignment(horizontal="left", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ì²« ë²ˆì§¸ í–‰ (ìŠ¤í‚¤ë§ˆ ì •ë³´) ìŠ¤íƒ€ì¼ ì ìš© - í—¤ë”ì™€ ë™ì¼í•˜ê²Œ
            for col in range(1, len(table_names) + 3):  # Package + Class + í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                cell = ws.cell(row=1, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë‘ ë²ˆì§¸ í–‰ (í—¤ë”) ìŠ¤íƒ€ì¼ ì ìš©
            for col in range(1, len(table_names) + 3):
                cell = ws.cell(row=2, column=col)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
                cell.border = thin_border
            
            # ë°ì´í„° í–‰ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(3, len(class_names) + 3):  # ë°ì´í„°ëŠ” 3í–‰ë¶€í„° ì‹œì‘
                for col in range(1, len(table_names) + 3):
                    cell = ws.cell(row=row, column=col)
                    cell.border = thin_border
                    
                    if col <= 2:  # Packageì™€ Class ì»¬ëŸ¼
                        cell.fill = class_fill
                        cell.font = Font(bold=False)  # ë³´í†µê¸€ì”¨
                        cell.alignment = left_alignment  # ì¢Œì¸¡ì •ë ¬
                    else:  # í…Œì´ë¸” ì»¬ëŸ¼ë“¤
                        cell.alignment = center_alignment
                        # CRUD ì—°ì‚°ì´ ìˆëŠ” ê²½ìš° êµµì€ê¸€ì”¨ë¡œ
                        if cell.value and cell.value != '-':
                            cell.font = Font(bold=True)
                        else:
                            cell.font = Font(bold=False)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 20)  # ìµœëŒ€ 20ìë¡œ ì œí•œ
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # ìš”ì•½ ì •ë³´ ì‹œíŠ¸ ì¶”ê°€
            summary_ws = wb.create_sheet("Summary")
            summary_data = [
                ["CRUD Matrix Summary", ""],
                ["Project Name", project_name],
                ["Total Classes", summary['total_classes']],
                ["Total Tables", summary['total_tables']],
                ["", ""],
                ["CRUD Operations", ""],
                ["Create (C)", summary['crud_stats']['C']],
                ["Read (R)", summary['crud_stats']['R']],
                ["Update (U)", summary['crud_stats']['U']],
                ["Delete (D)", summary['crud_stats']['D']],
                ["Other (O)", summary['crud_stats']['O']],
                ["", ""],
                ["Most Active Class", summary.get('most_active_class', 'N/A')],
                ["Most Used Table", summary.get('most_used_table', 'N/A')]
            ]
            
            for row_data in summary_data:
                summary_ws.append(row_data)
            
            # ìš”ì•½ ì‹œíŠ¸ ìŠ¤íƒ€ì¼ ì ìš©
            for row in range(1, len(summary_data) + 1):
                for col in range(1, 3):
                    cell = summary_ws.cell(row=row, column=col)
                    cell.border = thin_border
                    if row == 1:  # ì œëª© í–‰
                        cell.font = Font(bold=True, size=14)
                        cell.fill = header_fill
                        cell.alignment = center_alignment
                    elif col == 1:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ë¼ë²¨)
                        cell.font = Font(bold=True)
                        cell.fill = class_fill
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 15
            
            # íŒŒì¼ ì €ì¥
            wb.save(output_file)
            self.logger.info(f"Excel íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
            return True
            
        except ImportError as e:
            self.logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            self.logger.error("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install pandas openpyxl")
            return False
        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False

```

ì´ì œ ìˆ˜ì •ëœ Excel íŒŒì¼ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.


ì™„ë²½í•©ë‹ˆë‹¤! Excel íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 


## ğŸ¯ **CRUD Matrix Excel íŒŒì¼ ìŠ¤íƒ€ì¼ ìˆ˜ì • ì™„ë£Œ**

ìš”ì²­í•˜ì‹  ëª¨ë“  ìŠ¤íƒ€ì¼ ìˆ˜ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤:

### 1. **Package, Class ì»¬ëŸ¼ ìŠ¤íƒ€ì¼**
- âœ… **ì¢Œì¸¡ì •ë ¬**: `left_alignment` ì ìš©
- âœ… **ë³´í†µê¸€ì”¨**: `Font(bold=False)` ì ìš©

### 2. **Schema í–‰ ìŠ¤íƒ€ì¼**
- âœ… **í—¤ë”ì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼**: íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ ê¸€ì”¨, êµµì€ ê¸€ì”¨
- âœ… **Table í–‰ê³¼ ë™ì¼í•œ ìƒ‰ìƒ**: `header_fill` ì‚¬ìš©

### 3. **CRUD ì—°ì‚° í‘œì‹œ**
- âœ… **ìŠ¤í‚¤ë§ˆëª… ì œê±°**: `C, D, R, U (public)` â†’ `C, D, R, U`
- âœ… **êµµì€ê¸€ì”¨**: CRUD ì—°ì‚°ì´ ìˆëŠ” ì…€ì€ `Font(bold=True)` ì ìš©

### 4. **ìµœì¢… Excel íŒŒì¼ êµ¬ì¡°**
```
í–‰ 1: [ë¹ˆì¹¸] [ë¹ˆì¹¸] [public] [public] [public] ... (í—¤ë” ìŠ¤íƒ€ì¼)
í–‰ 2: [Package] [Class] [Table1] [Table2] [Table3] ... (í—¤ë” ìŠ¤íƒ€ì¼)
í–‰ 3: [íŒ¨í‚¤ì§€ëª…] [í´ë˜ìŠ¤ëª…] [C, D, R, U] [R] [C, R, U] ... (ë°ì´í„° ìŠ¤íƒ€ì¼)
```

### 5. **ìŠ¤íƒ€ì¼ íŠ¹ì§•**
- **Package/Class**: ì¢Œì¸¡ì •ë ¬, ë³´í†µê¸€ì”¨, ì—°í•œ íŒŒë€ìƒ‰ ë°°ê²½
- **Schema í–‰**: í—¤ë”ì™€ ë™ì¼í•œ ì§„í•œ íŒŒë€ìƒ‰ ë°°ê²½, í°ìƒ‰ êµµì€ ê¸€ì”¨
- **CRUD ì—°ì‚°**: êµµì€ ê¸€ì”¨ë¡œ ê°•ì¡° í‘œì‹œ
- **ë¹ˆ ì…€**: ë³´í†µ ê¸€ì”¨

### 6. **ìƒì„±ëœ íŒŒì¼**
- `final_crud_matrix.xlsx` - ìµœì¢… ìˆ˜ì •ëœ Excel íŒŒì¼

ì´ì œ Excel íŒŒì¼ì´ ìš”ì²­í•˜ì‹  ëª¨ë“  ìŠ¤íƒ€ì¼ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ë©°, ê°€ë…ì„±ê³¼ ì „ë¬¸ì„±ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!

```plaintext
í–‰ 1: [ë¹ˆì¹¸] [ë¹ˆì¹¸] [public] [public] [public] ... (í—¤ë” ìŠ¤íƒ€ì¼)
í–‰ 2: [Package] [Class] [Table1] [Table2] [Table3] ... (í—¤ë” ìŠ¤íƒ€ì¼)
í–‰ 3: [íŒ¨í‚¤ì§€ëª…] [í´ë˜ìŠ¤ëª…] [C, D, R, U] [R] [C, R, U] ... (ë°ì´í„° ìŠ¤íƒ€ì¼)
```

